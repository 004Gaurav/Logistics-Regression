{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Theoritical question"
      ],
      "metadata": {
        "id": "LE3H7QM-cldd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.  What is Logistic Regression, and how does it differ from Linear Regression ?\n",
        "\n",
        "- **Logistic Regression** is used when we want to **classify** things into categories, like yes or no, spam or not spam. It gives us a **probability** between 0 and 1 using a special S-shaped curve called the **sigmoid function**.\n",
        "\n",
        " **Linear Regression** is used to **predict numbers**, like predicting someone's salary based on their experience. It gives a straight-line output that can be any number, not just between 0 and 1.\n",
        "\n",
        " So, the main difference is:  \n",
        "  - **Logistic** = used for classification (yes/no).  \n",
        "  - **Linear** = used for prediction (numbers).\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "#2. What is the mathematical equation of Logistic Regression ?\n",
        "\n",
        "- The mathematical equation of **Logistic Regression** is:\n",
        "\n",
        "![WhatsApp Image 2025-04-24 at 22.17.44_d80b7efe.jpg](data:image/jpeg;base64,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)\n",
        "\n",
        "### Simple Breakdown:\n",
        "- \\( P(Y=1) \\): Probability that the output is 1 (true/positive).\n",
        "- \\( \\beta_0 \\): Intercept.\n",
        "- \\( \\beta_1, \\beta_2, ..., \\beta_n \\): Coefficients for input features.\n",
        "- \\( X_1, X_2, ..., X_n \\): Input features.\n",
        "- \\( e \\): Euler’s number (~2.718).\n",
        "\n",
        "This whole expression is the **sigmoid function**, which squashes any number into a value between 0 and 1 — perfect for probabilities.\n",
        "\n",
        "---\n",
        "\n",
        "#3. Why do we use the Sigmoid function in Logistic Regression ?\n",
        "\n",
        "- We use the **sigmoid function** in logistic regression because it transforms any input (which could be any real number, positive or negative) into a value between **0 and 1**. This range is exactly what we need when we’re working with **probabilities**.\n",
        "\n",
        "In logistic regression, we’re not trying to predict a number like in linear regression — we’re trying to predict whether something is **true or false**, **yes or no**, or **1 or 0**. The sigmoid function helps by turning the output into a **smooth probability**, which we can then interpret easily. If the result is close to 1, we predict “yes”; if it’s close to 0, we predict “no”.\n",
        "\n",
        "So, the sigmoid function is used because:\n",
        "- It maps outputs to a 0–1 range.\n",
        "- It gives a clear probability.\n",
        "- It’s perfect for binary classification tasks.\n",
        "---\n",
        "\n",
        "#4. What is the cost function of Logistic Regression ?\n",
        "\n",
        "- The **cost function of Logistic Regression** is called the **Log Loss** or **Binary Cross-Entropy Loss**.\n",
        "\n",
        "### The equation is:\n",
        "\n",
        "\\[\n",
        "J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)})) \\right]\n",
        "\\]\n",
        "\n",
        "### Simple Explanation:\n",
        "\n",
        "- \\( m \\): number of training examples  \n",
        "- \\( y^{(i)} \\): actual label (0 or 1)  \n",
        "- \\( h_\\theta(x^{(i)}) \\): predicted probability using the sigmoid function  \n",
        "- \\( \\log \\): natural logarithm  \n",
        "\n",
        "### Why this cost function?\n",
        "\n",
        "It **penalizes wrong predictions more heavily**. If the actual value is 1 but the model predicts a value close to 0, the loss becomes large — and vice versa. This helps the model learn better by reducing wrong predictions.\n",
        "\n",
        "----\n",
        "\n",
        "#5. What is Regularization in Logistic Regression? Why is it needed ?\n",
        "\n",
        "- **Regularization** is a technique used to **prevent overfitting** in logistic regression (and other models). It does this by **adding a penalty** to the cost function for having large values in the model’s coefficients.\n",
        "\n",
        " There are two common types:\n",
        "  - **L1 regularization (Lasso):** Can shrink some coefficients to zero — useful for feature selection.\n",
        "  - **L2 regularization (Ridge):** Shrinks coefficients but doesn’t usually make them zero — good for stability.\n",
        "\n",
        "  ### Why is Regularization Needed?\n",
        "\n",
        " Without regularization, the model might:\n",
        "  - Fit too closely to the training data (overfitting).\n",
        "  - Learn noise instead of patterns.\n",
        "  - Perform poorly on new/unseen data.\n",
        "\n",
        "  Regularization keeps the model **simple and general**, improving how well it works on real-world data.\n",
        "\n",
        "----\n",
        "\n",
        "#6. Explain the difference between Lasso, Ridge, and Elastic Net regression ?\n",
        "\n",
        "- **Ridge Regression (L2 Regularization)**  \n",
        "  It adds a penalty based on the **squares of the coefficients**. It reduces the size of the coefficients but doesn’t make them exactly zero. It’s useful when we want to reduce overfitting but keep all features.\n",
        "\n",
        "  **Lasso Regression (L1 Regularization)**  \n",
        "  It adds a penalty based on the **absolute values of the coefficients**. This can shrink some coefficients to **zero**, which means it also performs **feature selection**. It’s helpful when we want a simpler model with fewer features.\n",
        "\n",
        "  **Elastic Net Regression**  \n",
        "  It’s a **mix of Lasso and Ridge**. It includes both types of penalties. It works well when we have **many features**, especially if some are related or correlated.\n",
        "\n",
        "----\n",
        "\n",
        "#7. When should we use Elastic Net instead of Lasso or Ridge ?\n",
        "\n",
        "- We should use **Elastic Net** when:\n",
        "\n",
        "1. **There are many features**, and some of them are **highly correlated** (i.e., they give similar information).  \n",
        "   – Lasso tends to randomly pick one and drop others. Elastic Net handles this better by grouping them.\n",
        "\n",
        "2. We want **feature selection** (like Lasso) **and** **model stability** (like Ridge).  \n",
        "   – It gives a balance between reducing complexity and keeping important features.\n",
        "\n",
        "3. Lasso alone isn’t performing well (maybe it's dropping too many features), and Ridge keeps too many.  \n",
        "   – Elastic Net gives more control with a tuning parameter to mix both.\n",
        "\n",
        "---\n",
        "\n",
        "#8. What is the impact of the regularization parameter (λ) in Logistic Regression ?\n",
        "\n",
        "- The **regularization parameter (λ)** in logistic regression controls **how much penalty** we add to the model for having large coefficients.\n",
        "\n",
        "\n",
        "### Impact of λ:\n",
        "\n",
        "- **If λ is very small (close to 0):**  \n",
        "  – The penalty is weak, so the model behaves like **normal logistic regression**.  \n",
        "  – Can lead to **overfitting**, especially if the model is too complex.\n",
        "\n",
        "- **If λ is very large:**  \n",
        "  – The penalty is strong, so it forces the model to **shrink coefficients** a lot.  \n",
        "  – Can lead to **underfitting**, because the model becomes too simple.\n",
        "\n",
        "\n",
        "### In simple terms:\n",
        "\n",
        "- **Small λ → More flexible model → Risk of overfitting**  \n",
        "- **Large λ → Simpler model → Risk of underfitting**\n",
        "\n",
        "So, λ controls the **trade-off between fitting the data well and keeping the model simple**.\n",
        "\n",
        "---\n",
        "\n",
        "#9. What are the key assumptions of Logistic Regression ?\n",
        "\n",
        "-\n",
        "1. **Binary or categorical outcome:**  \n",
        "   The target variable should be **binary** (like 0/1, yes/no) for basic logistic regression. For more than two categories, we use **multinomial logistic regression**.\n",
        "\n",
        "2. **Independent observations:**  \n",
        "   Each data point should be **independent** of the others. No repeated or related data (like time series or grouped data).\n",
        "\n",
        "3. **Linearity of independent variables and log-odds:**  \n",
        "   Logistic regression assumes that the **logit** (log-odds) of the outcome is **linearly related** to the independent variables — **not** the outcome itself.\n",
        "\n",
        "4. **No multicollinearity:**  \n",
        "   The independent variables should **not be highly correlated** with each other. If they are, it can mess up the model’s estimates.\n",
        "\n",
        "5. **Large sample size:**  \n",
        "   Logistic regression works best with **enough data**. Small datasets can give unstable or unreliable results.\n",
        "\n",
        "---\n",
        "\n",
        "#10. What are some alternatives to Logistic Regression for classification tasks ?\n",
        "\n",
        "- **Alternatives to Logistic Regression for Classification Tasks:**\n",
        "\n",
        " - **Decision Tree**  \n",
        "   Splits data into branches based on feature values. Easy to understand but can overfit.\n",
        "\n",
        " - **Random Forest**  \n",
        "   Uses multiple decision trees to improve accuracy and reduce overfitting.\n",
        "\n",
        " - **Support Vector Machine (SVM)**  \n",
        "   Finds the best boundary between classes. Works well in high-dimensional spaces.\n",
        "\n",
        " - **Naive Bayes**  \n",
        "   Based on probability and assumes feature independence. Great for text data.\n",
        "\n",
        " - **K-Nearest Neighbors (KNN)**  \n",
        "   Classifies based on the majority class of nearest neighbors. Simple but can be slow on large data.\n",
        "\n",
        " - **Gradient Boosting (e.g., XGBoost, LightGBM, CatBoost)**  \n",
        "   Builds models in sequence to fix errors. High accuracy but more complex.\n",
        "\n",
        " - **Neural Networks (e.g., MLP)**  \n",
        "   Learns complex patterns. Useful for non-linear problems but needs more data and tuning.\n",
        "\n",
        "---\n",
        "\n",
        "#11. What are Classification Evaluation Metrics ?\n",
        "\n",
        "- **Classification Evaluation Metrics:**\n",
        "\n",
        " - **Accuracy**  \n",
        "  Percentage of correct predictions.  \n",
        "  `Accuracy = (TP + TN) / (TP + TN + FP + FN)`  \n",
        "  *(Good when classes are balanced)*\n",
        "\n",
        " - **Precision**  \n",
        "   How many predicted positives are actually correct.  \n",
        "   `Precision = TP / (TP + FP)`  \n",
        "   *(Good when false positives are costly)*\n",
        "\n",
        " - **Recall (Sensitivity / True Positive Rate)**  \n",
        "   How many actual positives are correctly identified.  \n",
        "   `Recall = TP / (TP + FN)`  \n",
        "   *(Good when false negatives are costly)*\n",
        "\n",
        " - **F1 Score**  \n",
        "   Harmonic mean of Precision and Recall.  \n",
        "   `F1 = 2 * (Precision * Recall) / (Precision + Recall)`  \n",
        "   *(Best when balance between precision and recall is needed)*\n",
        "\n",
        " - **Specificity (True Negative Rate)**  \n",
        "   How many actual negatives are correctly identified.  \n",
        "   `Specificity = TN / (TN + FP)`\n",
        "\n",
        " - **ROC-AUC (Receiver Operating Characteristic - Area Under Curve)**  \n",
        "   Measures the model's ability to distinguish between classes.  \n",
        "   *(Closer to 1 is better)*\n",
        "\n",
        " - **Confusion Matrix**  \n",
        "   Table showing TP, FP, TN, and FN.  \n",
        "   *(Gives a complete view of performance)*\n",
        "\n",
        "---\n",
        "\n",
        "#12. How does class imbalance affect Logistic Regression ?\n",
        "\n",
        "- **How Class Imbalance Affects Logistic Regression:**\n",
        "\n",
        " - Class imbalance means one class has many more samples than the other  \n",
        "  (e.g., 95% negative and 5% positive)\n",
        "\n",
        " - Logistic Regression may favor the majority class and predict it more often\n",
        "\n",
        " - You can get high accuracy by always predicting the majority class, but the model becomes useless for detecting the minority class\n",
        "\n",
        " - It often results in poor recall for the minority class (many false negatives)\n",
        "\n",
        " - Accuracy becomes a misleading metric in imbalanced scenarios\n",
        "\n",
        " **Ways to Handle Class Imbalance:**\n",
        "\n",
        " - Oversample the minority class (e.g., using SMOTE)\n",
        "\n",
        " - Undersample the majority class\n",
        "\n",
        " - Use `class_weight='balanced'` in Logistic Regression to give equal importance to both classes\n",
        "\n",
        " - Use evaluation metrics like Precision, Recall, F1 Score, and ROC-AUC instead of just Accuracy\n",
        "\n",
        " - Try models like Random Forest, XGBoost, or others that handle imbalance better\n",
        "\n",
        "----\n",
        "\n",
        "#13. What is Hyperparameter Tuning in Logistic Regression ?\n",
        "\n",
        "- It means adjusting the model’s settings to improve performance  \n",
        "- These settings are not learned during training, we set them before\n",
        "\n",
        "**Important Hyperparameters to Tune**\n",
        "\n",
        "- **C**  \n",
        "  Controls regularization strength  \n",
        "  Smaller C means stronger regularization (helps prevent overfitting)\n",
        "\n",
        "- **Penalty**  \n",
        "  Type of regularization used: `'l1'`, `'l2'`, `'elasticnet'`, or `'none'`\n",
        "\n",
        "- **Solver**  \n",
        "  Optimization algorithm used: `'liblinear'`, `'saga'`, `'lbfgs'`, `'newton-cg'`  \n",
        "  Some solvers only support certain penalties\n",
        "\n",
        "- **max_iter**  \n",
        "  Maximum number of iterations to let the algorithm run  \n",
        "  Useful if the model takes too long to converge\n",
        "\n",
        "**Why It’s Important**\n",
        "\n",
        "- Helps improve model performance on new data  \n",
        "- Prevents overfitting or underfitting  \n",
        "- Leads to better accuracy, precision, recall, etc.\n",
        "\n",
        "**How to Tune Hyperparameters**\n",
        "\n",
        "- **Grid Search**  \n",
        "  Tries every combination of settings you give\n",
        "\n",
        "- **Random Search**  \n",
        "  Picks random combinations to try (faster than grid search)\n",
        "\n",
        "- **Bayesian Optimization or libraries like Optuna**  \n",
        "  Smarter search techniques that often find better settings faster\n",
        "\n",
        "---\n",
        "\n",
        "#14. What are different solvers in Logistic Regression? Which one should be used ?\n",
        "\n",
        "\n",
        "- **liblinear**  \n",
        "  Suitable for small datasets  \n",
        "  Supports L1 and L2 regularization  \n",
        "  Works well for binary classification\n",
        "\n",
        " - **lbfgs**  \n",
        "   Fast and stable optimizer  \n",
        "   Supports only L2 regularization  \n",
        "   Good for multiclass classification  \n",
        "   Often the default choice\n",
        "\n",
        " - **newton-cg**  \n",
        "   Works with L2 regularization  \n",
        "   Better for large datasets and multiclass problems\n",
        "\n",
        " - **sag** (Stochastic Average Gradient)  \n",
        "   Good for large datasets  \n",
        "   Requires feature scaling  \n",
        "   Supports L2 regularization only\n",
        "\n",
        " - **saga**  \n",
        "   Supports L1, L2, and Elastic Net  \n",
        "   Works well on large-scale and sparse datasets  \n",
        "   Suitable for both binary and multiclass classification\n",
        "\n",
        " **Which Solver to Use**\n",
        "\n",
        " - Use **liblinear** for binary classification and small datasets, especially if you want L1 regularization  \n",
        " - Use **lbfgs** for multiclass problems and general use with L2 regularization  \n",
        " - Use **saga** if your data is large or sparse, or if you need L1 or Elastic Net regularization  \n",
        " - Use **sag** or **newton-cg** for large datasets with L2 regularization\n",
        "\n",
        "---\n",
        "\n",
        "#15. How is Logistic Regression extended for multiclass classification ?\n",
        "\n",
        "- Logistic Regression is naturally designed for **binary classification**, but it can be extended to handle **multiclass classification** using a few strategies:\n",
        "\n",
        " **1. One-vs-Rest (OvR or One-vs-All)**  \n",
        " - Trains one binary classifier for each class  \n",
        " - Each classifier learns to distinguish one class vs all others  \n",
        " - The class with the highest probability is chosen  \n",
        " - This is the **default** in many libraries like Scikit-learn\n",
        "\n",
        " **2. Multinomial (Softmax Regression)**  \n",
        " - Generalizes logistic regression to multiple classes directly  \n",
        " - Uses the **softmax function** to calculate probabilities for all classes at once  \n",
        " - Typically more accurate than OvR when classes are well-separated  \n",
        " - Requires solvers like **lbfgs**, **newton-cg**, or **saga**\n",
        "\n",
        " **3. One-vs-One (less common for logistic regression)**  \n",
        " - Trains a binary classifier for every pair of classes  \n",
        " - More often used in models like SVM rather than logistic regression\n",
        "\n",
        " **Which to Use?**\n",
        "\n",
        " - Use **OvR** if you want simplicity or are using **liblinear** solver  \n",
        " - Use **Multinomial** with **lbfgs** or **saga** solver for better performance on truly multiclass problems\n",
        "\n",
        "---\n",
        "\n",
        "#16. What are the advantages and disadvantages of Logistic Regression ?\n",
        "\n",
        "- **Advantages:**\n",
        "\n",
        " - **Simple and Interpretable**  \n",
        "  Easy to understand and interpret, especially with a linear decision boundary. It provides probabilities for predictions.\n",
        "\n",
        " - **Efficient to Train**  \n",
        "  Computationally efficient, even for larger datasets, and quick to train compared to more complex models.\n",
        "\n",
        " - **Works Well for Linearly Separable Data**  \n",
        "  If the data is linearly separable, logistic regression often performs well with minimal tuning.\n",
        "\n",
        " - **Probabilistic Output**  \n",
        "  Gives a probability score for each prediction, which is useful in certain applications (e.g., decision-making, risk prediction).\n",
        "\n",
        " - **Less Prone to Overfitting**  \n",
        "  Regularization (e.g., L1, L2) can be added easily to prevent overfitting, making it more robust in many scenarios.\n",
        "\n",
        " **Disadvantages:**\n",
        "\n",
        " - **Assumes Linearity**  \n",
        "  Assumes that the relationship between the independent variables and the log-odds of the dependent variable is linear. Not suitable for complex, non-linear relationships unless extended.\n",
        "\n",
        " - **Sensitive to Outliers**  \n",
        "  Logistic Regression can be sensitive to outliers in the data, which can negatively affect model performance.\n",
        "\n",
        " - **Poor Performance on Complex Datasets**  \n",
        "  Struggles with non-linear data or datasets where the decision boundary is not linear. May require feature engineering or transformations.\n",
        "\n",
        " - **Limited to Binary or Multiclass Extensions**  \n",
        "  Logistic Regression is designed for classification tasks, but it doesn’t handle regression or other types of tasks well.\n",
        "\n",
        " - **Needs Feature Scaling**  \n",
        "  Models can perform poorly if features are not scaled properly, especially when using solvers like **sag** or **saga**.\n",
        "\n",
        "---\n",
        "\n",
        "#17. What are some use cases of Logistic Regression ?\n",
        "\n",
        "- **Logistic Regression** is widely used in various applications across different industries due to its simplicity, interpretability, and effectiveness for classification tasks. Here are some common **use cases**:\n",
        "\n",
        "**1. Medical Diagnostics**  \n",
        " Used to predict the likelihood of a disease or condition based on patient data.  \n",
        " Example: Predicting whether a patient has diabetes based on features like age, BMI, and blood sugar levels.\n",
        "\n",
        "**2. Credit Scoring and Risk Assessment**  \n",
        " Helps financial institutions assess whether a borrower will default on a loan.  \n",
        " Example: Predicting if a customer will default on a loan based on income, credit score, and other financial data.\n",
        "\n",
        "**3. Marketing and Customer Segmentation**  \n",
        " Used to predict customer behaviors, such as whether a customer will buy a product or respond to a marketing campaign.  \n",
        " Example: Predicting whether a customer will purchase a product based on browsing history, demographics, and previous purchase behavior.\n",
        "\n",
        "**4. Email Spam Detection**  \n",
        " Classifies emails as spam or not spam based on email features like subject line, sender, and content.  \n",
        " Example: Classifying incoming emails into \"Spam\" or \"Not Spam\" based on certain keywords or email metadata.\n",
        "\n",
        "**5. Churn Prediction**  \n",
        " Used by companies to predict customer churn or the likelihood that a customer will leave a service.  \n",
        " Example: Predicting if a subscriber will cancel a subscription based on their usage, satisfaction, and customer support interactions.\n",
        "\n",
        "**6. Sentiment Analysis**  \n",
        " Classifies text data as positive, negative, or neutral sentiment based on customer reviews or social media posts.  \n",
        " Example: Predicting whether a review on a product is positive or negative based on the text of the review.\n",
        "\n",
        "**7. Fraud Detection**  \n",
        " Used in financial transactions to predict whether a transaction is fraudulent based on transaction history, customer behavior, and other variables.  \n",
        " Example: Predicting whether a credit card transaction is fraudulent based on the transaction's location, amount, and time.\n",
        "\n",
        "**8. Health Risk Prediction**  \n",
        " Predicts the likelihood of certain health outcomes based on lifestyle, genetic, and environmental factors.  \n",
        " Example: Predicting the likelihood of heart disease in a patient based on their lifestyle choices, medical history, and age.\n",
        "\n",
        "---\n",
        "\n",
        "#18. What is the difference between Softmax Regression and Logistic Regression ?\n",
        "\n",
        "-  **Logistic Regression**\n",
        "\n",
        " - Used for **binary classification** (two classes)\n",
        " - Outputs the **probability of one class** (e.g., class 1), and the other is just 1 minus that\n",
        " - Uses the **sigmoid** (logistic) function to map outputs to probabilities\n",
        " - Example: Predicting if an email is **spam** or **not spam**\n",
        "\n",
        " **Softmax Regression (Multinomial Logistic Regression)**\n",
        "\n",
        " - Used for **multiclass classification** (more than two classes)\n",
        " - Outputs the **probability for each class**, and all probabilities **sum to 1**\n",
        " - Uses the **softmax** function instead of sigmoid\n",
        " - Example: Predicting if a fruit is **apple**, **banana**, or **orange**\n",
        "\n",
        " **Key Differences**\n",
        "\n",
        " - Logistic Regression = binary → uses **sigmoid**\n",
        " - Softmax Regression = multiclass → uses **softmax**\n",
        " - Logistic Regression gives **1 probability**, Softmax gives **multiple probabilities**, one per class\n",
        "\n",
        "----\n",
        "\n",
        "#19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification ?\n",
        "\n",
        "-**One-vs-Rest (OvR)**\n",
        "\n",
        " It trains one binary classifier for each class  \n",
        " Each classifier tries to distinguish one class from all the others  \n",
        " The final prediction is the class with the highest confidence score or probability\n",
        "\n",
        " **Use OvR when:**\n",
        "\n",
        " You have a small or simple dataset  \n",
        " You are using the liblinear solver  \n",
        " The classes are clearly separable  \n",
        " You prefer a simpler, easier-to-interpret model\n",
        "\n",
        " **Softmax (Multinomial Logistic Regression)**\n",
        "\n",
        " It trains one model that considers all classes at the same time  \n",
        " It uses the softmax function to give a probability for each class  \n",
        " The class with the highest probability is selected as the prediction\n",
        "\n",
        " **Use Softmax when:**\n",
        "\n",
        " You have a larger or more complex dataset  \n",
        " You are using solvers like lbfgs, saga, or newton-cg  \n",
        " The classes are not clearly separated  \n",
        " You want better performance and more accurate probability estimates\n",
        "\n",
        " **Summary**\n",
        "\n",
        " Choose OvR for simplicity or small datasets  \n",
        " Choose Softmax for better accuracy in true multiclass situations\n",
        "\n",
        "----\n",
        "\n",
        "#20. How do we interpret coefficients in Logistic Regression ?\n",
        "\n",
        "- **What coefficients represent**\n",
        "\n",
        " Each coefficient shows the effect of a feature on the **log-odds** of the target being 1 (positive class)  \n",
        " They tell us how the **log-odds** change when that feature increases by one unit, keeping all other features constant\n",
        "\n",
        " **How to interpret**\n",
        "\n",
        " If a coefficient is **positive**  \n",
        " It means that as the feature increases, the **odds of the positive class increase**  \n",
        " Example: A positive coefficient for \"Age\" means older people are more likely to be in the positive class\n",
        "\n",
        " If a coefficient is **negative**  \n",
        " It means that as the feature increases, the **odds of the positive class decrease**  \n",
        " Example: A negative coefficient for \"Price\" means higher prices make it less likely to belong to the positive class\n",
        "\n",
        " **To make it more intuitive**\n",
        "\n",
        " We can convert the coefficient to an **odds ratio** by taking `exp(coefficient)`  \n",
        " If the odds ratio is greater than 1, it increases the odds  \n",
        " If it is less than 1, it decreases the odds  \n",
        " Example: A coefficient of 0.7 → `exp(0.7) ≈ 2` means the odds are **twice as high**\n",
        "\n",
        " **Intercept (bias term)**\n",
        "\n",
        " The intercept represents the log-odds of the outcome when all features are zero  \n",
        " It helps shift the decision boundary left or right\n",
        "\n"
      ],
      "metadata": {
        "id": "YU_Yt91OcyCJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical Question"
      ],
      "metadata": {
        "id": "xYRoBwqR08X9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcMq-064cObo",
        "outputId": "a9e34b94-380e-480a-cff3-616f9e55ef5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "#1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Scale the features (important for regularization)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Logistic Regression model with L1 penalty\n",
        "model = LogisticRegression(penalty='l1', solver='saga', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and calculate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy with L1 Regularization:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llGYDCGa1jeL",
        "outputId": "58a93d91-40ab-4e7c-e714-b95577b8800d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L1 Regularization: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with L2 regularization\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy with L2 Regularization:\", accuracy)\n",
        "\n",
        "# Print coefficients\n",
        "print(\"Model Coefficients:\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtMl1jzA15yj",
        "outputId": "96152058-2fb1-4a60-a831-e80cd8b73423"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L2 Regularization: 1.0\n",
            "Model Coefficients:\n",
            "[[-1.02102589  1.1315509  -1.81471682 -1.68763103]\n",
            " [ 0.53439559 -0.28357112 -0.34273213 -0.73103351]\n",
            " [ 0.4866303  -0.84797979  2.15744895  2.41866455]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet').\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with Elastic Net regularization\n",
        "model = LogisticRegression(\n",
        "    penalty='elasticnet',\n",
        "    solver='saga',       # 'saga' is required for elasticnet\n",
        "    l1_ratio=0.5,        # Mix between L1 and L2 (0 = L2, 1 = L1)\n",
        "    max_iter=200\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and calculate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy with Elastic Net Regularization:\", accuracy)\n",
        "\n",
        "# Print coefficients\n",
        "print(\"Model Coefficients:\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVslgUHI2MxO",
        "outputId": "7bf5a781-2009-4d28-9570-a1bc2a3f5463"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Elastic Net Regularization: 1.0\n",
            "Model Coefficients:\n",
            "[[-0.82334661  1.17475171 -1.96486618 -1.70811516]\n",
            " [ 0.07999475  0.          0.         -0.37230691]\n",
            " [ 0.         -0.65342027  2.74206127  3.06904625]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with One-vs-Rest multiclass strategy\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and calculate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy with One-vs-Rest Strategy:\", accuracy)\n",
        "\n",
        "# Print coefficients\n",
        "print(\"Model Coefficients:\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wxJM9Vm2bBM",
        "outputId": "252a86ec-f4d5-4e6b-949a-b9d7d8204acd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with One-vs-Rest Strategy: 0.9666666666666667\n",
            "Model Coefficients:\n",
            "[[-0.76560747  1.33826997 -1.6082868  -1.42234276]\n",
            " [ 0.26117413 -1.23992478  0.53679084 -0.73948844]\n",
            " [ 0.04512377 -0.22445255  1.75763427  2.42627487]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']  # liblinear supports both l1 and l2\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=200), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Predict using best model\n",
        "best_model = grid.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Print results\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Test Set Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic29HEvo2lBe",
        "outputId": "418cd5b0-1013-416a-e25c-85622b92ce5e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Test Set Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Set up Stratified K-Fold Cross-Validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Create Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Evaluate the model using Stratified K-Fold Cross-Validation\n",
        "cv_scores = cross_val_score(model, X_scaled, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "# Print the average accuracy\n",
        "print(f\"Average Accuracy: {np.mean(cv_scores):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_KXr9M72qdr",
        "outputId": "22208811-8072-4d9b-9b48-84bad4b74e6d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.9533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Load dataset from a CSV file\n",
        "# Replace 'your_dataset.csv' with the actual file path\n",
        "df = pd.read_csv('/content/spotify.csv')\n",
        "\n",
        "# Check for non-numeric columns\n",
        "print(df.dtypes)\n",
        "\n",
        "# If there are categorical columns (e.g., 'Artist'), we need to encode them\n",
        "# Assuming 'Artist' is a categorical column (replace with the actual column name)\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Encode categorical variables using Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "for col in categorical_columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "# Assume the target variable is the last column in the dataset\n",
        "X = df.iloc[:, :-1]  # All columns except the last one (features)\n",
        "y = df.iloc[:, -1]   # Last column (target variable)\n",
        "\n",
        "# Scale the features (important for regularization)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3mOKhX73BaO",
        "outputId": "42fad471-487a-4e6c-c803-252b4d6f304b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artist           object\n",
            "Track Name       object\n",
            "Popularity        int64\n",
            "Duration (ms)     int64\n",
            "Track ID         object\n",
            "dtype: object\n",
            "Model Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Load dataset from a CSV file\n",
        "# Replace 'your_dataset.csv' with the actual file path\n",
        "df = pd.read_csv('/content/spotify.csv')\n",
        "\n",
        "# Check for non-numeric columns and encode them\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Apply label encoding to categorical columns\n",
        "for col in categorical_columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "# Assume the target variable is the last column in the dataset\n",
        "X = df.iloc[:, :-1]  # All columns except the last one (features)\n",
        "y = df.iloc[:, -1]   # Last column (target variable)\n",
        "\n",
        "# Scale the features (important for regularization)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Define the hyperparameter grid for RandomizedSearchCV\n",
        "param_distributions = {\n",
        "    'C': uniform(0.001, 100),  # Random values between 0.001 and 100\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],  # L1, L2, and ElasticNet regularization\n",
        "    'solver': ['liblinear', 'saga']  # Solvers that support L1, L2, and ElasticNet\n",
        "}\n",
        "\n",
        "# Perform RandomizedSearchCV with a smaller n_splits (e.g., 3)\n",
        "random_search = RandomizedSearchCV(model, param_distributions, n_iter=100, cv=3, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters from the RandomizedSearchCV\n",
        "print(\"Best Parameters from RandomizedSearchCV:\", random_search.best_params_)\n",
        "\n",
        "# Predict on the test set using the best model\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Set Accuracy with Best Hyperparameters:\", accuracy)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhzvG1W34HVg",
        "outputId": "a0d00f6e-31eb-4e0f-9cd2-7b4d03a9169b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "87 fits failed out of a total of 300.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "33 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "54 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1203, in fit\n",
            "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
            "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.08807765 0.08807765        nan 0.07953064        nan 0.07668164\n",
            " 0.002849   0.07100777 0.08807765 0.08237964        nan 0.05113719\n",
            " 0.08807765        nan 0.08237964 0.08237964 0.07100777        nan\n",
            " 0.07955478 0.03694046 0.08237964 0.08237964        nan 0.08237964\n",
            " 0.08522864 0.08522864 0.08237964 0.08237964 0.07668164 0.08522864\n",
            " 0.08522864 0.03124245        nan        nan 0.08237964 0.08237964\n",
            " 0.08522864        nan        nan        nan 0.08807765 0.08807765\n",
            "        nan 0.08807765 0.08237964        nan 0.08237964 0.08807765\n",
            "        nan 0.08237964        nan 0.08522864 0.08237964 0.08237964\n",
            " 0.07668164        nan 0.07953064 0.08807765 0.08237964 0.07668164\n",
            " 0.08237964        nan 0.08237964 0.08237964 0.08522864 0.08807765\n",
            " 0.08522864 0.08237964 0.07668164        nan 0.07670578        nan\n",
            "        nan 0.08237964 0.08522864 0.08807765 0.08237964        nan\n",
            "        nan        nan        nan        nan 0.08237964 0.07668164\n",
            " 0.07955478 0.08237964 0.08237964        nan        nan        nan\n",
            " 0.08237964 0.08237964 0.08237964 0.08807765 0.08237964 0.08237964\n",
            " 0.08807765 0.08237964        nan 0.08237964]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters from RandomizedSearchCV: {'C': np.float64(37.455011884736244), 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Test Set Accuracy with Best Hyperparameters: 0.09090909090909091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "# Load dataset from a CSV file\n",
        "# Replace 'your_dataset.csv' with the actual file path\n",
        "df = pd.read_csv('/content/spotify.csv')\n",
        "\n",
        "# Check for non-numeric columns and encode them\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Apply label encoding to categorical columns\n",
        "for col in categorical_columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "# Assume the target variable is the last column in the dataset\n",
        "X = df.iloc[:, :-1]  # All columns except the last one (features)\n",
        "y = df.iloc[:, -1]   # Last column (target variable)\n",
        "\n",
        "# Scale the features (important for regularization)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the One-vs-One classifier using Logistic Regression\n",
        "log_reg = LogisticRegression(max_iter=200)\n",
        "ovo_classifier = OneVsOneClassifier(log_reg)\n",
        "ovo_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = ovo_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"One-vs-One (OvO) Multiclass Logistic Regression Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f6ZhuCY5Xz6",
        "outputId": "fb59f863-c730-428a-de28-068d088e9eb1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-One (OvO) Multiclass Logistic Regression Accuracy: 0.022727272727272728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset from a CSV file\n",
        "# Replace 'your_dataset.csv' with the actual file path\n",
        "df = pd.read_csv('/content/spotify.csv')\n",
        "\n",
        "# Check for non-numeric columns and encode them\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Apply label encoding to categorical columns\n",
        "for col in categorical_columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "# Assume the target variable is the last column in the dataset\n",
        "X = df.iloc[:, :-1]  # All columns except the last one (features)\n",
        "y = df.iloc[:, -1]   # Last column (target variable)\n",
        "\n",
        "# Scale the features (important for regularization)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix using seaborn\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "uVi1DGPZ6Lw2",
        "outputId": "9a915e5e-e5fb-4452-b2d0-fdb2fda56f55"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load dataset from a CSV file\n",
        "# Replace 'your_dataset.csv' with the actual file path\n",
        "df = pd.read_csv('/content/spotify.csv')\n",
        "\n",
        "# Check for non-numeric columns and encode them\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Apply label encoding to categorical columns\n",
        "for col in categorical_columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "# Assume the target variable is the last column in the dataset\n",
        "X = df.iloc[:, :-1]  # All columns except the last one (features)\n",
        "y = df.iloc[:, -1]   # Last column (target variable)\n",
        "\n",
        "# Scale the features (important for regularization)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Precision, Recall, F1-Score, and Accuracy (with average='macro' for multiclass)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Model Accuracy: {accuracy}\")\n",
        "print(f\"Precision (Macro Average): {precision}\")\n",
        "print(f\"Recall (Macro Average): {recall}\")\n",
        "print(f\"F1-Score (Macro Average): {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5bBcBsC7DUr",
        "outputId": "c818f00f-82aa-4bc6-bf33-1cf3e1426bc7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.0\n",
            "Precision (Macro Average): 0.0\n",
            "Recall (Macro Average): 0.0\n",
            "F1-Score (Macro Average): 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance .\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load dataset from a CSV file\n",
        "# Replace 'your_dataset.csv' with the actual file path\n",
        "df = pd.read_csv('/content/spotify.csv')\n",
        "\n",
        "# Check for non-numeric columns and encode them\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Apply label encoding to categorical columns\n",
        "for col in categorical_columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "# Assume the target variable is the last column in the dataset\n",
        "X = df.iloc[:, :-1]  # All columns except the last one (features)\n",
        "y = df.iloc[:, -1]   # Last column (target variable)\n",
        "\n",
        "# Scale the features (important for regularization)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the Logistic Regression model with class weights\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Precision, Recall, F1-Score, and Accuracy (with average='macro' for multiclass)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Model Accuracy: {accuracy}\")\n",
        "print(f\"Precision (Macro Average): {precision}\")\n",
        "print(f\"Recall (Macro Average): {recall}\")\n",
        "print(f\"F1-Score (Macro Average): {f1}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF_AULKB8bkH",
        "outputId": "09f931c2-acd1-44a8-e760-4f4b7f774cf7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.03409090909090909\n",
            "Precision (Macro Average): 0.015587529976019183\n",
            "Recall (Macro Average): 0.02158273381294964\n",
            "F1-Score (Macro Average): 0.01644398766700925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the Titanic dataset from a CSV file\n",
        "# Replace 'titanic.csv' with the actual file path\n",
        "df = pd.read_csv('/content/titanic.csv')\n",
        "\n",
        "# Display the first few rows to understand the dataset structure\n",
        "print(df.head())\n",
        "\n",
        "# Handle missing values\n",
        "# For numerical columns, we will fill missing values with the median of that column\n",
        "# For categorical columns, we will fill missing values with the mode (most frequent value)\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Apply imputer to numerical columns\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
        "\n",
        "# Apply imputer to categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
        "\n",
        "# Drop columns like 'Name', 'Ticket', 'Cabin' that are non-numeric or won't be used in the model\n",
        "df = df.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Encode categorical columns (like 'Sex', 'Embarked') into numeric using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the 'Sex' column (binary)\n",
        "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
        "\n",
        "# Encode the 'Embarked' column (categorical with more than 2 categories)\n",
        "df['Embarked'] = label_encoder.fit_transform(df['Embarked'])\n",
        "\n",
        "# Feature selection - Use all columns except 'Survived' for features\n",
        "X = df.drop(columns=['Survived'])  # Features (excluding target 'Survived')\n",
        "y = df['Survived']  # Target variable (Survived or not)\n",
        "\n",
        "# Scale the features (important for regularization in Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Precision, Recall, F1-Score, and Accuracy\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Model Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra5tY3Gs83Sf",
        "outputId": "2f6ef478-ca61-4e29-b9c0-09724504c28d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "Model Accuracy: 0.8100558659217877\n",
            "Precision: 0.7857142857142857\n",
            "Recall: 0.7432432432432432\n",
            "F1-Score: 0.7638888888888888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Titanic dataset from a CSV file\n",
        "# Replace 'titanic.csv' with the actual file path\n",
        "df = pd.read_csv('/content/titanic.csv')\n",
        "\n",
        "# Display the first few rows to understand the dataset structure\n",
        "print(df.head())\n",
        "\n",
        "# Handle missing values\n",
        "# For numerical columns, we will fill missing values with the median of that column\n",
        "# For categorical columns, we will fill missing values with the mode (most frequent value)\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Apply imputer to numerical columns\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
        "\n",
        "# Apply imputer to categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
        "\n",
        "# Drop columns like 'Name', 'Ticket', 'Cabin' that are non-numeric or won't be used in the model\n",
        "df = df.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Encode categorical columns (like 'Sex', 'Embarked') into numeric using LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the 'Sex' column (binary)\n",
        "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
        "\n",
        "# Encode the 'Embarked' column (categorical with more than 2 categories)\n",
        "df['Embarked'] = label_encoder.fit_transform(df['Embarked'])\n",
        "\n",
        "# Feature selection - Use all columns except 'Survived' for features\n",
        "X = df.drop(columns=['Survived'])  # Features (excluding target 'Survived')\n",
        "y = df['Survived']  # Target variable (Survived or not)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Logistic Regression model without scaling\n",
        "model_no_scaling = LogisticRegression(max_iter=200)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "\n",
        "# Calculate accuracy without scaling\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "print(f\"Accuracy without scaling: {accuracy_no_scaling}\")\n",
        "\n",
        "# Apply feature scaling (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the Logistic Regression model with scaling\n",
        "model_with_scaling = LogisticRegression(max_iter=200)\n",
        "model_with_scaling.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_with_scaling = model_with_scaling.predict(X_test_scaled)\n",
        "\n",
        "# Calculate accuracy with scaling\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_with_scaling)\n",
        "print(f\"Accuracy with scaling: {accuracy_with_scaling}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFYDQpjk-Irr",
        "outputId": "1227bf17-0c0d-4743-b9d5-60065eda05ec"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "Accuracy without scaling: 0.8044692737430168\n",
            "Accuracy with scaling: 0.8100558659217877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Titanic dataset from a CSV file\n",
        "# Replace 'titanic.csv' with the actual file path\n",
        "df = pd.read_csv('/content/titanic.csv')\n",
        "\n",
        "# Display the first few rows to understand the dataset structure\n",
        "print(df.head())\n",
        "\n",
        "# Handle missing values\n",
        "# For numerical columns, we will fill missing values with the median of that column\n",
        "# For categorical columns, we will fill missing values with the mode (most frequent value)\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Apply imputer to numerical columns\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
        "\n",
        "# Apply imputer to categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
        "\n",
        "# Drop columns like 'Name', 'Ticket', 'Cabin' that are non-numeric or won't be used in the model\n",
        "df = df.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Encode categorical columns (like 'Sex', 'Embarked') into numeric using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the 'Sex' column (binary)\n",
        "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
        "\n",
        "# Encode the 'Embarked' column (categorical with more than 2 categories)\n",
        "df['Embarked'] = label_encoder.fit_transform(df['Embarked'])\n",
        "\n",
        "# Feature selection - Use all columns except 'Survived' for features\n",
        "X = df.drop(columns=['Survived'])  # Features (excluding target 'Survived')\n",
        "y = df['Survived']  # Target variable (Survived or not)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features (important for regularization in Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict probabilities on the test set\n",
        "y_pred_prob = model.predict_proba(X_test_scaled)[:, 1]  # Get probabilities for the positive class\n",
        "\n",
        "# Calculate the ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "print(f\"ROC-AUC Score: {roc_auc}\")\n",
        "\n",
        "# Plot ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "id": "1lJlX9WhIiZa",
        "outputId": "af469c3a-d2fd-4371-e0a8-ce7855c5ccda"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "ROC-AUC Score: 0.8755469755469755\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the Titanic dataset from a CSV file\n",
        "# Replace 'titanic.csv' with the actual file path\n",
        "df = pd.read_csv('/content/titanic.csv')\n",
        "\n",
        "# Display the first few rows to understand the dataset structure\n",
        "print(df.head())\n",
        "\n",
        "# Handle missing values\n",
        "# For numerical columns, we will fill missing values with the median of that column\n",
        "# For categorical columns, we will fill missing values with the mode (most frequent value)\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Apply imputer to numerical columns\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
        "\n",
        "# Apply imputer to categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
        "\n",
        "# Drop columns like 'Name', 'Ticket', 'Cabin' that are non-numeric or won't be used in the model\n",
        "df = df.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Encode categorical columns (like 'Sex', 'Embarked') into numeric using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the 'Sex' column (binary)\n",
        "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
        "\n",
        "# Encode the 'Embarked' column (categorical with more than 2 categories)\n",
        "df['Embarked'] = label_encoder.fit_transform(df['Embarked'])\n",
        "\n",
        "# Feature selection - Use all columns except 'Survived' for features\n",
        "X = df.drop(columns=['Survived'])  # Features (excluding target 'Survived')\n",
        "y = df['Survived']  # Target variable (Survived or not)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features (important for regularization in Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create and train the Logistic Regression model with custom C (C=0.5)\n",
        "model = LogisticRegression(C=0.5, max_iter=200, solver='liblinear')\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with C=0.5: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA9Pl0VgI7zs",
        "outputId": "6c96e72f-d71f-47ba-f40a-e8920ade34d8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "Accuracy with C=0.5: 0.8044692737430168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#18. Write a Python program to train Logistic Regression and identify important features based on model coefficients.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the Titanic dataset from a CSV file\n",
        "# Replace 'titanic.csv' with the actual file path\n",
        "df = pd.read_csv('/content/titanic.csv')\n",
        "\n",
        "# Display the first few rows to understand the dataset structure\n",
        "print(df.head())\n",
        "\n",
        "# Handle missing values\n",
        "# For numerical columns, we will fill missing values with the median of that column\n",
        "# For categorical columns, we will fill missing values with the mode (most frequent value)\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Apply imputer to numerical columns\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
        "\n",
        "# Apply imputer to categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
        "\n",
        "# Drop columns like 'Name', 'Ticket', 'Cabin' that are non-numeric or won't be used in the model\n",
        "df = df.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Encode categorical columns (like 'Sex', 'Embarked') into numeric using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the 'Sex' column (binary)\n",
        "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
        "\n",
        "# Encode the 'Embarked' column (categorical with more than 2 categories)\n",
        "df['Embarked'] = label_encoder.fit_transform(df['Embarked'])\n",
        "\n",
        "# Feature selection - Use all columns except 'Survived' for features\n",
        "X = df.drop(columns=['Survived'])  # Features (excluding target 'Survived')\n",
        "y = df['Survived']  # Target variable (Survived or not)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features (important for regularization in Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get model coefficients\n",
        "coefficients = model.coef_[0]  # Get the coefficients of the features\n",
        "feature_names = X.columns  # Get the feature names\n",
        "\n",
        "# Create a DataFrame to display the feature names and their corresponding coefficients\n",
        "coeff_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefficients\n",
        "})\n",
        "\n",
        "# Sort the features by the absolute value of the coefficients to identify the most important ones\n",
        "coeff_df['Abs_Coefficient'] = coeff_df['Coefficient'].abs()\n",
        "coeff_df = coeff_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
        "\n",
        "# Display the features sorted by importance\n",
        "print(coeff_df[['Feature', 'Coefficient', 'Abs_Coefficient']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LArfitymJedw",
        "outputId": "e0df1c54-f341-4052-83be-a8f0e1d9472d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "       Feature  Coefficient  Abs_Coefficient\n",
            "2          Sex    -1.286470         1.286470\n",
            "1       Pclass    -0.776618         0.776618\n",
            "3          Age    -0.394737         0.394737\n",
            "4        SibSp    -0.338884         0.338884\n",
            "7     Embarked    -0.170738         0.170738\n",
            "6         Fare     0.129088         0.129088\n",
            "5        Parch    -0.107262         0.107262\n",
            "0  PassengerId     0.094139         0.094139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa Score.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the Titanic dataset from a CSV file\n",
        "# Replace 'titanic.csv' with the actual file path\n",
        "df = pd.read_csv('/content/titanic.csv')\n",
        "\n",
        "# Display the first few rows to understand the dataset structure\n",
        "print(df.head())\n",
        "\n",
        "# Handle missing values\n",
        "# For numerical columns, we will fill missing values with the median of that column\n",
        "# For categorical columns, we will fill missing values with the mode (most frequent value)\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Apply imputer to numerical columns\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
        "\n",
        "# Apply imputer to categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
        "\n",
        "# Drop columns like 'Name', 'Ticket', 'Cabin' that are non-numeric or won't be used in the model\n",
        "df = df.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Encode categorical columns (like 'Sex', 'Embarked') into numeric using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the 'Sex' column (binary)\n",
        "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
        "\n",
        "# Encode the 'Embarked' column (categorical with more than 2 categories)\n",
        "df['Embarked'] = label_encoder.fit_transform(df['Embarked'])\n",
        "\n",
        "# Feature selection - Use all columns except 'Survived' for features\n",
        "X = df.drop(columns=['Survived'])  # Features (excluding target 'Survived')\n",
        "y = df['Survived']  # Target variable (Survived or not)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features (important for regularization in Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate Cohen's Kappa score\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Cohen's Kappa Score: {kappa_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUhIMXd_JsX-",
        "outputId": "76e62acb-8cbe-4f14-fdd5-c8769d84147e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "Cohen's Kappa Score: 0.605215360664245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the Titanic dataset from a CSV file\n",
        "# Replace 'titanic.csv' with the actual file path\n",
        "df = pd.read_csv('/content/titanic.csv')\n",
        "\n",
        "# Display the first few rows to understand the dataset structure\n",
        "print(df.head())\n",
        "\n",
        "# Handle missing values\n",
        "# For numerical columns, we will fill missing values with the median of that column\n",
        "# For categorical columns, we will fill missing values with the mode (most frequent value)\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Apply imputer to numerical columns\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
        "\n",
        "# Apply imputer to categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
        "\n",
        "# Drop columns like 'Name', 'Ticket', 'Cabin' that are non-numeric or won't be used in the model\n",
        "df = df.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Encode categorical columns (like 'Sex', 'Embarked') into numeric using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the 'Sex' column (binary)\n",
        "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
        "\n",
        "# Encode the 'Embarked' column (categorical with more than 2 categories)\n",
        "df['Embarked'] = label_encoder.fit_transform(df['Embarked'])\n",
        "\n",
        "# Feature selection - Use all columns except 'Survived' for features\n",
        "X = df.drop(columns=['Survived'])  # Features (excluding target 'Survived')\n",
        "y = df['Survived']  # Target variable (Survived or not)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features (important for regularization in Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get the predicted probabilities for the positive class (class 1)\n",
        "y_pred_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Compute precision and recall values\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
        "\n",
        "# Plot Precision-Recall curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, marker='.', color='b')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        },
        "id": "JABhhO4HK8AD",
        "outputId": "b28b1d98-736a-403f-ee0d-c0efca9d9d77"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAIjCAYAAAAQgZNYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXD5JREFUeJzt3Xl4VNXh//HPZMhCgAAaEpaENSCKCAjCFxERCkRQLLZVCggYw6LAT0tqUVyIaBWxilDLbgC1VnDDoiIQI1hBFGWxqKhBQAxLWFTCItnm/v64nUkmmYQkzHaT9+t58kzuudu5Oab9cHLuOTbDMAwBAAAAFhQS6AoAAAAAVUWYBQAAgGURZgEAAGBZhFkAAABYFmEWAAAAlkWYBQAAgGURZgEAAGBZhFkAAABYFmEWAAAAlkWYBVBj3H777WrZsmWlztm4caNsNps2btzokzpZ3XXXXafrrrvOtb1//37ZbDYtX748YHUCULMQZgH4zPLly2Wz2VxfERERateunSZPnqzs7OxAVy/oOYOh8yskJEQXXXSRBg0apC1btgS6el6RnZ2te++9V+3bt1dkZKTq1Kmjrl276q9//at++eWXQFcPgAXUCnQFAFR/jz76qFq1aqVz585p06ZNWrBggdasWaMvv/xSkZGRfqvHkiVL5HA4KnXOtddeq19//VVhYWE+qtX5DR8+XIMHD1ZhYaG+++47zZ8/X3379tVnn32mjh07BqxeF+qzzz7T4MGDdfr0ad12223q2rWrJOnzzz/Xk08+qf/85z9av359gGsJINgRZgH43KBBg9StWzdJ0tixY3XxxRdr9uzZ+ve//63hw4d7POfMmTOqU6eOV+sRGhpa6XNCQkIUERHh1XpU1pVXXqnbbrvNtd27d28NGjRICxYs0Pz58wNYs6r75ZdfdPPNN8tut2vHjh1q37692/7HH39cS5Ys8cq9fPHfEoDgwTADAH7Xr18/SdK+ffskmWNZ69atq++//16DBw9WvXr1NHLkSEmSw+HQnDlz1KFDB0VERCg2NlYTJkzQzz//XOq67733nvr06aN69eopKipKV111lf71r3+59nsaM7tixQp17drVdU7Hjh01d+5c1/6yxsy+9tpr6tq1q2rXrq3o6GjddtttOnjwoNsxzuc6ePCghg4dqrp166pRo0a69957VVhYWOWfX+/evSVJ33//vVv5L7/8oj/96U+Kj49XeHi4EhISNGvWrFK90Q6HQ3PnzlXHjh0VERGhRo0a6frrr9fnn3/uOmbZsmXq16+fYmJiFB4erssuu0wLFiyocp1LWrRokQ4ePKjZs2eXCrKSFBsbq4ceesi1bbPZ9Mgjj5Q6rmXLlrr99ttd286hLR9++KEmTpyomJgYxcXF6fXXX3eVe6qLzWbTl19+6Sr75ptv9Ic//EEXXXSRIiIi1K1bN61evfrCHhqAT9AzC8DvnCHs4osvdpUVFBQoMTFR11xzjZ5++mnX8IMJEyZo+fLlSkpK0t133619+/bpH//4h3bs2KHNmze7eluXL1+uO+64Qx06dNC0adPUoEED7dixQ2vXrtWIESM81iM9PV3Dhw/Xb37zG82aNUuStHv3bm3evFn33HNPmfV31ueqq67SzJkzlZ2drblz52rz5s3asWOHGjRo4Dq2sLBQiYmJ6tGjh55++mm9//77euaZZ9SmTRvdddddVfr57d+/X5LUsGFDV9nZs2fVp08fHTx4UBMmTFDz5s318ccfa9q0aTp8+LDmzJnjOjY5OVnLly/XoEGDNHbsWBUUFOijjz7SJ5984upBX7BggTp06KCbbrpJtWrV0ttvv62JEyfK4XBo0qRJVap3catXr1bt2rX1hz/84YKv5cnEiRPVqFEjTZ8+XWfOnNENN9ygunXr6tVXX1WfPn3cjl25cqU6dOigyy+/XJL01VdfqVevXmrWrJnuv/9+1alTR6+++qqGDh2qN954QzfffLNP6gygigwA8JFly5YZkoz333/fOHbsmPHjjz8aK1asMC6++GKjdu3aRlZWlmEYhjFmzBhDknH//fe7nf/RRx8ZkoyXX37ZrXzt2rVu5b/88otRr149o0ePHsavv/7qdqzD4XB9P2bMGKNFixau7XvuuceIiooyCgoKynyGDRs2GJKMDRs2GIZhGHl5eUZMTIxx+eWXu93rnXfeMSQZ06dPd7ufJOPRRx91u2aXLl2Mrl27lnlPp3379hmSjBkzZhjHjh0zjhw5Ynz00UfGVVddZUgyXnvtNdexjz32mFGnTh3ju+++c7vG/fffb9jtduPAgQOGYRjGBx98YEgy7r777lL3K/6zOnv2bKn9iYmJRuvWrd3K+vTpY/Tp06dUnZctW1buszVs2NDo1KlTuccUJ8lITU0tVd6iRQtjzJgxrm3nf3PXXHNNqXYdPny4ERMT41Z++PBhIyQkxK2NfvOb3xgdO3Y0zp075ypzOBzG1VdfbbRt27bCdQbgHwwzAOBz/fv3V6NGjRQfH68//vGPqlu3rlatWqVmzZq5HVeyp/K1115T/fr1NWDAAB0/ftz11bVrV9WtW1cbNmyQZPawnjp1Svfff3+p8a02m63MejVo0EBnzpxRenp6hZ/l888/19GjRzVx4kS3e91www1q37693n333VLn3HnnnW7bvXv31t69eyt8z9TUVDVq1EiNGzdW7969tXv3bj3zzDNuvZqvvfaaevfurYYNG7r9rPr376/CwkL95z//kSS98cYbstlsSk1NLXWf4j+r2rVru74/efKkjh8/rj59+mjv3r06efJkhetelpycHNWrV++Cr1OWcePGyW63u5UNGzZMR48edRsy8vrrr8vhcGjYsGGSpJ9++kkffPCBbr31Vp06dcr1czxx4oQSExOVmZlZajgJgMBimAEAn5s3b57atWunWrVqKTY2VpdccolCQtz/LV2rVi3FxcW5lWVmZurkyZOKiYnxeN2jR49KKhq24PwzcUVNnDhRr776qgYNGqRmzZpp4MCBuvXWW3X99deXec4PP/wgSbrkkktK7Wvfvr02bdrkVuYck1pcw4YN3cb8Hjt2zG0Mbd26dVW3bl3X9vjx43XLLbfo3Llz+uCDD/T3v/+91JjbzMxM/fe//y11L6fiP6umTZvqoosuKvMZJWnz5s1KTU3Vli1bdPbsWbd9J0+eVP369cs9/3yioqJ06tSpC7pGeVq1alWq7Prrr1f9+vW1cuVK/eY3v5FkDjHo3Lmz2rVrJ0nas2ePDMPQww8/rIcfftjjtY8ePVrqH2IAAocwC8Dnunfv7hqLWZbw8PBSAdfhcCgmJkYvv/yyx3PKCm4VFRMTo507d2rdunV677339N5772nZsmUaPXq0XnjhhQu6tlPJ3kFPrrrqKldIlsye2OIvO7Vt21b9+/eXJN14442y2+26//771bdvX9fP1eFwaMCAAZo6darHezjDWkV8//33+s1vfqP27dtr9uzZio+PV1hYmNasWaNnn3220tObedK+fXvt3LlTeXl5FzTtWVkv0hXvWXYKDw/X0KFDtWrVKs2fP1/Z2dnavHmznnjiCdcxzme79957lZiY6PHaCQkJVa4vAO8jzAIIWm3atNH777+vXr16eQwnxY+TpC+//LLSQSMsLExDhgzRkCFD5HA4NHHiRC1atEgPP/ywx2u1aNFCkvTtt9+6ZmVw+vbbb137K+Pll1/Wr7/+6tpu3bp1ucc/+OCDWrJkiR566CGtXbtWkvkzOH36tCv0lqVNmzZat26dfvrppzJ7Z99++23l5uZq9erVat68uavcOazDG4YMGaItW7bojTfeKHN6tuIaNmxYahGFvLw8HT58uFL3HTZsmF544QVlZGRo9+7dMgzDNcRAKvrZh4aGnvdnCSA4MGYWQNC69dZbVVhYqMcee6zUvoKCAle4GThwoOrVq6eZM2fq3LlzbscZhlHm9U+cOOG2HRISoiuuuEKSlJub6/Gcbt26KSYmRgsXLnQ75r333tPu3bt1ww03VOjZiuvVq5f69+/v+jpfmG3QoIEmTJigdevWaefOnZLMn9WWLVu0bt26Usf/8ssvKigokCT9/ve/l2EYmjFjRqnjnD8rZ29y8Z/dyZMntWzZsko/W1nuvPNONWnSRH/+85/13Xffldp/9OhR/fWvf3Vtt2nTxjXu12nx4sWVnuKsf//+uuiii7Ry5UqtXLlS3bt3dxuSEBMTo+uuu06LFi3yGJSPHTtWqfsB8D16ZgEErT59+mjChAmaOXOmdu7cqYEDByo0NFSZmZl67bXXNHfuXP3hD39QVFSUnn32WY0dO1ZXXXWVRowYoYYNG+qLL77Q2bNnyxwyMHbsWP3000/q16+f4uLi9MMPP+i5555T586ddemll3o8JzQ0VLNmzVJSUpL69Omj4cOHu6bmatmypaZMmeLLH4nLPffcozlz5ujJJ5/UihUr9Je//EWrV6/WjTfeqNtvv11du3bVmTNntGvXLr3++uvav3+/oqOj1bdvX40aNUp///vflZmZqeuvv14Oh0MfffSR+vbtq8mTJ2vgwIGuHusJEybo9OnTWrJkiWJiYirdE1qWhg0batWqVRo8eLA6d+7stgLY9u3b9corr6hnz56u48eOHas777xTv//97zVgwAB98cUXWrdunaKjoyt139DQUP3ud7/TihUrdObMGT399NOljpk3b56uueYadezYUePGjVPr1q2VnZ2tLVu2KCsrS1988cWFPTwA7wrkVAoAqjfnNEmfffZZuceNGTPGqFOnTpn7Fy9ebHTt2tWoXbu2Ua9ePaNjx47G1KlTjUOHDrkdt3r1auPqq682ateubURFRRndu3c3XnnlFbf7FJ+a6/XXXzcGDhxoxMTEGGFhYUbz5s2NCRMmGIcPH3YdU3JqLqeVK1caXbp0McLDw42LLrrIGDlypGuqsfM9V2pqqlGR//l1TnP1t7/9zeP+22+/3bDb7caePXsMwzCMU6dOGdOmTTMSEhKMsLAwIzo62rj66quNp59+2sjLy3OdV1BQYPztb38z2rdvb4SFhRmNGjUyBg0aZGzbts3tZ3nFFVcYERERRsuWLY1Zs2YZS5cuNSQZ+/btcx1X1am5nA4dOmRMmTLFaNeunREREWFERkYaXbt2NR5//HHj5MmTruMKCwuN++67z4iOjjYiIyONxMREY8+ePWVOzVXef3Pp6emGJMNmsxk//vijx2O+//57Y/To0Ubjxo2N0NBQo1mzZsaNN95ovP766xV6LgD+YzOMcv4GBwAAAAQxxswCAADAsgizAAAAsCzCLAAAACyLMAsAAADLIswCAADAsgizAAAAsKwat2iCw+HQoUOHVK9ePdlstkBXBwAAACUYhqFTp06padOmCgkpv++1xoXZQ4cOKT4+PtDVAAAAwHn8+OOPiouLK/eYGhdm69WrJ8n84URFRfn8fvn5+Vq/fr1rGU5YD21ofbSh9dGG1kb7WZ+/2zAnJ0fx8fGu3FaeGhdmnUMLoqKi/BZmIyMjFRUVxS+wRdGG1kcbWh9taG20n/UFqg0rMiSUF8AAAABgWYRZAAAAWBZhFgAAAJZFmAUAAIBlEWYBAABgWYRZAAAAWBZhFgAAAJZFmAUAAIBlEWYBAABgWYRZAAAAWBZhFgAAAJZFmAUAAIBlEWYBAABgWYRZAAAAWFZAw+x//vMfDRkyRE2bNpXNZtNbb7113nM2btyoK6+8UuHh4UpISNDy5ct9Xk8AAAAEp4CG2TNnzqhTp06aN29ehY7ft2+fbrjhBvXt21c7d+7Un/70J40dO1br1q3zcU2rLitL2rUrWllZZe/fsEFV2n8h5/ry2tQreK5NvQAA1V2tQN580KBBGjRoUIWPX7hwoVq1aqVnnnlGknTppZdq06ZNevbZZ5WYmOiralZZWpo0fnwtORy9NH26oTvvlPr3L9r//vvSwoWSYUg2myq1/0LO9eW1q2O9CgpsWraso9atq1Vjnrk61CskRFq8WEpOFgCgGrMZhmEEuhKSZLPZtGrVKg0dOrTMY6699lpdeeWVmjNnjqts2bJl+tOf/qSTJ096PCc3N1e5ubmu7ZycHMXHx+v48eOKioryVvVLycqSEhJqyeGw+eweAMpntxvKzCxQbGy+0tPTNWDAAIWGhga6WqiC/Hza0MpoP+vzdxvm5OQoOjpaJ0+ePG9eC2jPbGUdOXJEsbGxbmWxsbHKycnRr7/+qtq1a5c6Z+bMmZoxY0ap8vXr1ysyMtJndd21K1oOR69S5c2bn1SdOgU6c6aWDhyoX6X9kqp8ri+vTb2C59rUy1RYaNPLL3+qjh1PSJLS09NLnQtroQ2tjfazPn+14dmzZyt8rKV6Ztu1a6ekpCRNmzbNVbZmzRrdcMMNOnv2rMcwG0w9s85eori4C9svBee1q2u99u8v0CWXRMgwas4zV7d60TNrffTsWRvtZ33B3DMrI0hIMlatWlXuMb179zbuuecet7KlS5caUVFRFb7PyZMnDUnGyZMnq1DLynn+ecOw2x2GZH4+/7yn/cb/9huV2n8h5/ry2tWxXnl5ecakSduLtWX1f2Yr18tmM/eFhBTty8vLM9566y0jLy/PgDXRhtZG+1mfv9uwMnnNUj2z9913n9asWaNdu3a5ykaMGKGffvpJa9eurdB9cnJyVL9+/YolfS/Yty9fL7/8qUaO7KFWrUr/SyYrS9qzR0pIkOLiSp9f3v4LOdeX165u9crPz9eaNWt0xRWD9cMPoTXima1cr/79pYwM6amnpL/8xSxztuHgwYPpFbIo2tDaaD/r83cbViavBXTM7OnTp7Vnzx7X9r59+7Rz505ddNFFat68uaZNm6aDBw/qxRdflCTdeeed+sc//qGpU6fqjjvu0AcffKBXX31V7777bqAe4bzi4qSOHU94/D9k5/6y9p1v/4Wc68trV+d6tWrlu2sH6zNbrV7O0UYXXVT2+QCA6iOg88x+/vnn6tKli7p06SJJSklJUZcuXTR9+nRJ0uHDh3XgwAHX8a1atdK7776r9PR0derUSc8884yef/75oJyWCwAAAL4X0J7Z6667TuWNcvC0utd1112nHTt2+LBWAAAAsIqA9swCAAAAF4IwCwAAAMsizAIAAMCyCLMAAACwLMIsAAAALIswCwAAAMsizAIAAMCyCLMAAACwLMIsAAAALIswCwAAAMsizAKAH2RlSRs2mJ9V2Q8A8IwwCwAVVNVAmpYmtWgh9etnfi5ZIp04IX3zjbRpkzR5stS8edH+tDTfPwsAVBe1Al0BAAgmWVlSZqbUtq0UF1dUnpYmjR8vORxSSIi0eLGUnCwZhnTmjDRvnvTAA+Z+m0265RYpIUHat0965ZWi6zgc5nXGj/d8f4dDmjBBSkx0vz8AwDPCLIAapaywKpUOrA88IPXsKX39tTR1qhlcJXP/2LHSQw9JP/8s5ea6X8cwpFdfPX9dGjSQIiOlQ4fcywsLpT17CLMAUBGEWQDVyq+/mp8//eRe7nBIf/+7TVOnFvWe/u535p/3jxyRfvhB+vhj9+P/+tfy73XkSPn7f/c7qVUrafbsoiAsSXa7GahbtTLDdYsW5v2K709IOP+zAgAIswCqkbQ0KSPD/H7qVGnFCiksTDp0qJYOHhyiwsKi1wQMQ3rjjfNfMyHB7CH98EP3QBoSIr39ttShg9kze+mlpQPp3LnmuZdeag4dKCw0yxctMoOsZO5fvNjs6XWet2gRvbIAUFGEWQDVQlZW6XGo27c7v7P976u0YcOk7t2lWrWkKVNKB9ING8xgmZZWOpAOHlx07OLFpfc7A2lysjkGds+eonBcXHJyUZj9/HOpc+cq/hAAoAYizAKoFjIz3YOo06OPSv36FWjz5k2aNq2PHI6iUGu3S08/XRQu69S5sEBa3v64uIr1tjZtWomHBgAQZgFUD23bmn/6L9mzmpQkxcYaOn78pBYsKNTEibU8hlXpwgNpRQMrAMB7CLMAqgXn2FNPPav5+eYxSUmGBg8uO6w6r0MgBQDrIMwCqDbO17MqEVYBoLohzAKoVgirAFCzsJwtAAAALIswCwAAAMsizAIAAMCyCLMAAACwLMIsAAAALIswCwAAAMsizAJAEDl0KNA1AABrIcwCQIClpRV937Wr+zYAoHyEWQAIoKwsafz4om2Hw1ySNysrcHUCACshzAJAAGVmmgG2uMJCc0leAMD5EWYBIIDatpVCSvwvsd0uJSQEpj4AYDWEWQAIoLg4afHiom27XVq0yCwHAJwfYRYAAiw5uej7zz933wYAlI8wCwBBpGnTQNcAAKyFMAsAAADLIswCAADAsgizAAAAsCzCLAAAACyLMAsAKFNWlrRhAyuSAQhehFkAqOE8BVaHQ3rqKal5c6lfP6lFCyktLXB1BICy1Ap0BQAAvpWVZS6b27Zt6cUYFi+W7rrLDK82m9S9u5SfL339tXTuXNFxDoc0YYKUmMiCDgCCC2EWACyuvLCaliaNH2+G0ZAQKSlJiomRdu+W/vtfae/eomMNQ/r007LvU1go7dlDmAUQXAizAGBhJcPqggXS1VebQXXzZmn+/KJjHY6KDRV47DGpd29zeIHDUVRut0sJCd5/BgC4EIRZALCAkr2vhiFt3SqNG2d+LxUNBTifIUOk/v2l6Ghp1KjSgfX22817LF4sjR1rloeESIsW0SsLIPgQZgEgiBw6ZA4DKG7ePOnuu4vGtbZpIx07Jp086fkatWtLXbpIrVpJ//pXUdiVzLA6f35RKP31VzMAFxaa+4oH1uRkaepU6aefpPXrpd/8xvvPCwAXijALAAFW/E//XbtK/+//SbGx0o4d0mefSfv3F+03DHPcqmSGz8JC92vZ7dK330rx8eZ2375lh1XJDKyJieY1ExJK97za7eZn48ZeeVQA8DrCLAAEUFaWOebVyeGQ5s49/3nPP28OEXjppdJh1RlkpfOHVcksY/gAAKsizAJAAGVmuo9ZderbV7r+ejNkehrXmpgohYURVgGAMAsAAdS2rflyVcmw+uKLFRvXKhFWAdRsrAAGAAHknDXAOTa1rHGt+/ebq3Tt329uVwcslQvAG+iZBYAAq65DBcpazMHhkGbNkh580HyhLSTEDPTVJaQD8C/CLAAEASuGVanswFpyMYdbb5Xq1jUXc9i1yxw64cRSuQAuBGEWAFAlJQPrww+bPcubN0sLFxYd53BIK1aUfy2WygVQVYRZAECZnPPYHjkidehgfn/smJSeXnr1sRkzyr/WbbeZq4/FxJgLMLBULgBvIMwCADxKSzNX/5KkAQOkyy83tw8eLPucK64wVx978cXSK4/NnFnU8zpnjrmqmXMfS+UCqCpmMwAAlFJyMQfDMMe6OoNsy5alz7HbpXfflZYvl5YsKX+GhlGjir7PzOTlLwBVR5gFAJRS1mIOf/+7lJMj7dtnrkJWVmCtzHRi9MgCuBAMMwAAlFLWYg433yzVq2dun29KMavO0ADAWgLeMztv3jy1bNlSERER6tGjh7Zu3Vrmsfn5+Xr00UfVpk0bRUREqFOnTlq7dq0fawsANUNFFnNwHnfddYRWAIET0DC7cuVKpaSkKDU1Vdu3b1enTp2UmJioo0ePejz+oYce0qJFi/Tcc8/p66+/1p133qmbb75ZO3bs8HPNAaD6q64rjwGoXgIaZmfPnq1x48YpKSlJl112mRYuXKjIyEgtXbrU4/EvvfSSHnjgAQ0ePFitW7fWXXfdpcGDB+uZZ57xc80BoGag5xVAsAvYmNm8vDxt27ZN06ZNc5WFhISof//+2rJli8dzcnNzFRER4VZWu3Ztbdq0qcz75ObmKjc317Wdk5MjyRyykJ+ffyGPUCHOe/jjXvAN2tD6aMPgYzZF6P++P3+70IbWRvtZn7/bsDL3CViYPX78uAoLCxUbG+tWHhsbq2+++cbjOYmJiZo9e7auvfZatWnTRhkZGXrzzTdV6JzV24OZM2dqhoeZvNevX6/IyMgLe4hKSE9P99u94Bu0ofXRhsHj9Olakm6QJP3znxsUG/tr+Sf8D21obbSf9fmrDc+ePVvhYy01m8HcuXM1btw4tW/fXjabTW3atFFSUlKZwxIkadq0aUpJSXFt5+TkKD4+XgMHDlRUVJTP65yfn6/09HQNGDBAoaGhPr8fvI82tD7aMPjMm2dzfX/XXQO0YEGhkpKMMo+nDa2N9rM+f7eh8y/pFRGwMBsdHS273a7s7Gy38uzsbDVu3NjjOY0aNdJbb72lc+fO6cSJE2ratKnuv/9+tW7dusz7hIeHKzw8vFR5aGioX3+h/H0/eB9taH20YXDIypL+/OeibYfDpokTa2nw4POPzaUNrY32sz5/tWFl7hGwF8DCwsLUtWtXZWRkuMocDocyMjLUs2fPcs+NiIhQs2bNVFBQoDfeeEO//e1vfV1dAICXeFqQobDQnK8WACoroMMMUlJSNGbMGHXr1k3du3fXnDlzdObMGSUlJUmSRo8erWbNmmnmzJmSpE8//VQHDx5U586ddfDgQT3yyCNyOByaOnVqIB8DAFAJZS3IkJAQuDoBsK6Ahtlhw4bp2LFjmj59uo4cOaLOnTtr7dq1rpfCDhw4oJCQos7jc+fO6aGHHtLevXtVt25dDR48WC+99JIaNGgQoCcAAFRWXJw0Z450993mdlkLMgBARQT8BbDJkydr8uTJHvdt3LjRbbtPnz76+uuv/VArAIAvjRpVFGYzM6VWrQJbHwDWFfDlbAEANRs9sgAuBGEWAAAAlkWYBQAAgGURZgEAAGBZhFkAAABYFmEWABCUsrKkDRvMTwAoC2EWABBQJcNqYaE0Y4bUvLnUr5/UooW0bJktMJUDEPQCPs8sAKDmeemlou8TEqQpU6T69aXNm82v06eL9jsc0sSJdi1aFOH/igIIeoRZAIBfZWVJf/pT0bbDIT3zTPnnFBbadPhwHZ/Wq6KyssyFHtq2ZY5cIBgwzAAA4FeZmWaALalvX+m556T33pNsJUYV2O2GmjQ5458KliMtzRz24Bz+kJYW6BoBoGcWAOBXbdtKISHugdZul158sain85ZbpFdfLdo3f36hoqPP+aV+JXteHQ7pu++kNWuke++VDMM8zuGQJkyQEhPpoQUCiZ5ZAIBfxcVJixebIVUyPxctcg+EPXqYn/37S/v3S0lJhl/qVrzntXlzqUMH6eKLpUsvlf7856Ig61RYKO3Z45eqASgDPbMAAL9LTjZ7NPfsMV8AK6tns3Fjc19+vvfuXbznNTZW+u9/pU8/lTIypDffLDrOMKSvvza/j4iQOnaUPvvM/Vp2u1l/AIFDmAUABERcnO/+PF/WS1rPPuvew1qrllRQUP61Fi2SkpKk0FBp7NiicbKeepQB+B9hFgBQraSlSePHm2NaQ0Kk0aPNzw0bpH373I8tKJCioqSePc2hBHPnug8lsNulwYPNICtJffqY17/qKrMXlyALBB5hFgBgOZ56XvPzpXXrpHHj3F/SWr68/GutWmWOkZWkyy83X+oqLCy/5/WiiwiyQLAgzAIALKVkz+sNN0hnzkiffCKdPev5nOHDpYEDzbG6JWdRaNeuaLuiY3kBBA/CLAAgaB05YvbCxsZKp0/X0gsv2DR+vHvP69tvFx0fFSXl5Lhfw26XnnrKDKaFhefveb2QsbwsqAD4H1NzAQCCzqefmp/vv29OkZWQUEujRg3WuHG1Sk2PJZnL4e7aJf38s/T882VP+5WcbE71tWGD+Zmc7L06s6ACEBj0zAIAgkpWlvTaa0XbhiEdOGAuCdaypaEffrCVekkrJcU9sJY3VMAbsyicOGHW03mdH34oGvogsaAC4E/0zAIAgkpmZunFCSRp6tSt+u67Ai1ZUv6CC5K5fd113g+SH35ofn7+udn7etNN5ljcSy8tvUQvCyoA/kHPLAAgqHhe7tZQu3Y/SwrcS1pZWdLSpUXbJcfrlsSCCoB/0DMLAAgqnpa7nT+/UNHR59yO8UXPa3nK6jH+05+knTvNOjuFhLCgAuAvhFkAQNAp+aJWUpKHFOlnzh7j4ux2c0WxTp3M+W3/7//M8n/8w7svlwEoG2EWABCUAtH7Wh5PPcYle18jIszPiy/2f/2AmooxswAAVBCLKgDBhzALAEAlsKgCEFwYZgAAgB+wqALgG4RZAAC85Nz/Jlw4ccL8NAxzSMIzz5gviJVcVCErKzD1BKoThhkAAOAFaWnSJ5+Y30+caM5Je/CgdPiw5+Odiyow3AC4MPTMAgBwgbKyzOVsi/v8czPIhoZKXbtKNpv7fhZVALyDMAsAwAXKzCy9nK0kPfusdPKkGWyfeKKovKxleAFUHmEWAIALVNaCCn/4g1S7trk9bJj5GRFhLgTBogqAdxBmAQC4QBVZUMHJbqdHFvAmXgADAMALvLGgAvPQApVHzywAAF5yIUvwMg8tUDWEWQAA/Kiw0H1+2QMHpDlzmIcWqCqGGQAA4AcrV5qf585JzZtLPXtKhw6ZL4N5wjy0QMXQMwsAgI9lZUkPPli0bRjSxx+bQdZulzp3Ln0O89ACFUOYBQDAx8qah3bWLOnnn6UdO6QbbigqZx5aoOIIswAA+FhZ89COGCHVq2dud+lift58M/PQApVBmAUAwMcqMw9tXBw9skBl8AIYAAB+4I15aAGURpgFAMBP6HUFvI9hBgAABJGsLOaXBSqDMAsAQBDYscP8XLWKFcCAyiDMAgAQYFlZ0po1RdusAAZUHGEWAIAAy8w0F1IozrkCGIDyEWYBAAiwtm0lm829jBXAgIohzAIAEGBxcdLgwUXbrAAGVBxhFgCAIMAKYEDVEGYBAAgizEULVA5hFgAAAJZFmAUAIIiwaAJQOYRZAACCAIsmAFVDmAUAIMBYNAGoOsIsAAABxqIJQNURZgEACDAWTQCqjjALAECAsWgCUHWEWQAAggCLJgBVQ5gFACCIsGgCUDkBD7Pz5s1Ty5YtFRERoR49emjr1q3lHj9nzhxdcsklql27tuLj4zVlyhSdO3fOT7UFAABAMAlomF25cqVSUlKUmpqq7du3q1OnTkpMTNTRo0c9Hv+vf/1L999/v1JTU7V7926lpaVp5cqVeuCBB/xccwAAfINFE4DKCWiYnT17tsaNG6ekpCRddtllWrhwoSIjI7V06VKPx3/88cfq1auXRowYoZYtW2rgwIEaPnz4eXtzAQAIdiyaAFRNrUDdOC8vT9u2bdO0adNcZSEhIerfv7+2bNni8Zyrr75a//znP7V161Z1795de/fu1Zo1azRq1Kgy75Obm6vc3FzXdk5OjiQpPz9f+fn5Xnqasjnv4Y97wTdoQ+ujDa2vurehuWhCLUnm/FzmogmG+vUrqBbjZ6t7+9UE/m7DytwnYGH2+PHjKiwsVGxsrFt5bGysvvnmG4/njBgxQsePH9c111wjwzBUUFCgO++8s9xhBjNnztSMGTNKla9fv16RkZEX9hCVkJ6e7rd7wTdoQ+ujDa2vurbhrl3RMoxebmWFhTa9/PKn6tjxRIBq5X3Vtf1qEn+14dmzZyt8bMDCbFVs3LhRTzzxhObPn68ePXpoz549uueee/TYY4/p4Ycf9njOtGnTlJKS4trOyclRfHy8Bg4cqKioKJ/XOT8/X+np6RowYIBCQ0N9fj94H21ofbSh9VX3NrziCmn6dEOGUbRygt1uaOTIHtWmZ7Y6t19N4O82dP4lvSICFmajo6Nlt9uVnZ3tVp6dna3GjRt7POfhhx/WqFGjNHbsWElSx44ddebMGY0fP14PPvigQkJKDwEODw9XeHh4qfLQ0FC//kL5+37wPtrQ+mhD66uubdiqlblowrvvmtvmogk2tWpVvZ61urZfTeKvNqzMPQL2AlhYWJi6du2qjIwMV5nD4VBGRoZ69uzp8ZyzZ8+WCqx2u12SZJRc1BoAAAth0QSgagI6zCAlJUVjxoxRt27d1L17d82ZM0dnzpxRUlKSJGn06NFq1qyZZs6cKUkaMmSIZs+erS5duriGGTz88MMaMmSIK9QCAGBlLJoAVE5Aw+ywYcN07NgxTZ8+XUeOHFHnzp21du1a10thBw4ccOuJfeihh2Sz2fTQQw/p4MGDatSokYYMGaLHH388UI8AAACAAAr4C2CTJ0/W5MmTPe7buHGj23atWrWUmpqq1NRUP9QMAAD/cy6aQO8sUDEBX84WAAD4dtGErCxpwwZWFkP1RJgFACDAzEUTirbNRRO8Ez7T0sxw3K8fK4uheiLMAgAQYJmZUslJeQoLpT17Kn4NT72v27dL48aZ4VjybkgGgkXAx8wCAFDTtW0r2WzugdZulxISKnZ+Wpo0frwZVkNCpBtvlA4flj77rPSxzpDMmFxUF/TMAgAQYHFx5qIJTuaiCRULnN99V7r3dfVqz0HWee2KhmTACgizAAAEgfMtmlB8GMH+/dK8edKgQdLll5ceoiBJf/mLdOiQ9PzzZq+vZH5WNCQDVsEwAwAAgoinRROWLJHuvLOo9/V87Hbp7rulJk3MULxqlblU7owZrCyG6oeeWQAAgohzntlff5XeflsaPrxoPGxxPXpITz0lff21GXadC2F6GqIQGWl+Nmzon2cA/ImeWQAAgkDxeWZXrZLCwqS8vLKPf/JJ6brrzO8vvVS6/nrzxa6EhNI9u2fPmp8//+z1agMBR88sAAABVnKeWckMsk2bSklJ5gwFxXl6iSsuzgy3JYNsWpo5xECSUlOZZxbVD2EWAIAA8zTPrCT985/S0qXS4sXlDyMoS1aWOUTByTCYZxbVD8MMAAAIsLZtzd7X4uNi7XazXDJf2kpMLHsYQVkyM0uPtWWeWVQ39MwCABBgcXHn730taxhBeZwhuTjmmUV1Q5gFACAIJCeb88du2OB5ntmqcIbk880z62kpXMAqCLMAAASJqvS+nk9yctHqYp7mmU1Lk1q0kPr1Mz95QQxWQ5gFAKCaK2ue2R9/dJ/D1uHgBTFYD2EWAIBqrvg8s3l5UkaGdM890lVXlf2CGGAVzGYAAEA1Vnye2enTpSeekM6dK/t4XhCD1dAzCwBANVVynlnJDLIXX2yOnX3rLWn27KJ9lZnDFggW9MwCAFBNeZpnVpJefdV84UuSTp+WUlLM73fvLprbtrisLPNabdsSdBF86JkFAKCaKmue2XbtPB9fMqgahrkEbvPmzHaA4EWYBQCgmqrIYgzFZWVJubnSunXSpElSs2bSo48WLbXLbAcIRgwzAACgGjvfUrgvvFD0fbt2Uni4GWjLwnK4CDaEWQAAqrm4OM/hMytLuvtu97LcXCkmRho6VLr6aikpqahnVmK2AwQfwiwAADVUWS+IvfJK0Qtia9dKK1aY3zPbAYIRY2YBAKihKvKCWM+e5mffvtL+/aWXwwUCjTALAEANVdkXxIBgRJgFAKAGS042e1w3bPDc87pli/m5YQNTcyE4EWYBAKjh4uKk664r3SOblSWtXFm0zdRcCEaEWQAA4FFmpvtMBlLR1FxAsCDMAgAAj9q2lWw297KSU3NlZZlDEHzRW+vLa6P6IMwCAACP4uKkYcOKtku+IJaWZo6j9cVSt768NqoXwiwAAChTWVNz/fCDNH580Ty1VRlP66nntbBQWrVKGjfuwq6NmqNKiyYUFhZq+fLlysjI0NGjR+UoMePyBx984JXKAQCA4PHrr9Lq1dJbb0lvvFF6wYXKLHWbllYUhkNCzLB65oy0Zo10/Hjp41lGF2WpUpi95557tHz5ct1www26/PLLZSs5oAYAAFQLxafmKr6YgicVXeo2K6t0r+6CBUX7o6KknJzzXzsry3xJrW1bQm5NVqUwu2LFCr366qsaPHiwt+sDAACCRMmpuZySkqTbbjN7SidMMMtCQjwvuJCVJe3ebdPRoxH69FOb3nvPXC7X0zK6t9wiTZwo9eolvfiiNHasWe5pMYeSPbuLF7M6WU1VpTAbFhamhIr80wsAAFiWp6m5JGn0aHNe2n79pDlzpN27pZdekkaMcD9uwQJp0iTJMGpJGiip7L/k2u3S7NlFgTU52Tw3N1fatEn6v/8zyw1DWrfOHFPrrJtzTG1iIj20NVGVXgD785//rLlz58rw9F84AACoFtq2NXs9izvfUIJjx6Rly6SBA81e1qKoYJNk6MYbzeA7Z07Fl9H99Vfp7bfNwBoXJw0axPy3KFKlntlNmzZpw4YNeu+999ShQweFhoa67X/zzTe9UjkAABA4cXHmn+8nTDDDoqepuXbvNr+/7TbpkUek77/3PITAZNOf/2z26krS739vBtCEhNJBNi3N7JWVzB7g4mrXNgNucRUdr4vqp0phtkGDBrr55pu9XRcAABBkkpPNP9+XDJ3Ol7icDMMcliBJXbqYU3nNmeMebO12QwkJRUMN4uI898aWvLbT7bdLf/yj1KePdPfd0pIlzuuW37OL6q1KYXbZsmXergcAAAhSnkJnZqbnHthXXjEDpyRddllRr25IiEPz5zsUF3f+6FHWtceMKerV7dvXDLMJCdK//iVddVXlngnVxwUtmnDs2DFt2rRJmzZt0rFjx7xVJwAAEOTKGk97zTVF28nJ5kIL6ekFWrw4XUlJFXvXpiJjdTdsMD/37DFfDmOFsJqrSmH2zJkzuuOOO9SkSRNde+21uvbaa9W0aVMlJyfr7Nmz3q4jAAAIMs7xtOd7iSsuTurTx1B09DmvXTsrS3r++aLjWSGsZqtSmE1JSdGHH36ot99+W7/88ot++eUX/fvf/9aHH36oP//5z96uIwAACELOntcNG9yXuvX1tT1NGcZsBjVXlcbMvvHGG3r99dd1nXPgiqTBgwerdu3auvXWW7Wg+DIeAACg2irrJS5fXrttW8lmcw+0zGZQc1WpZ/bs2bOKjY0tVR4TE8MwAwAA4FNxcUWrg0nMZlDTVSnM9uzZU6mpqTp3rmj8y6+//qoZM2aoZ8+eXqscAACAJ337mp9dunh/iAOspUrDDObOnavExETFxcWpU6dOkqQvvvhCERERWrdunVcrCAAAAJSlSmH28ssvV2Zmpl5++WV98803kqThw4dr5MiRql27tlcrCAAAUJJzaq4dO6QWLczZD+idrZmqFGYlKTIyUuPGjfNmXQAAAM6rrKm5EhMZN1sTVTjMrl69WoMGDVJoaKhWr15d7rE33XTTBVcMAADAk/Km5io+F21mpjnzAQG3eqtwmB06dKiOHDmimJgYDR06tMzjbDabCgsLvVE3AACAUs43NVdamjR+vNljGxJStSEIhGHrqPBsBg6HQzExMa7vy/oiyAIAAF8qb2quzz+Xxo0zg6xUtdXB0tLMcbj9+pmfLJUb3Ko0NZcnv/zyi7cuBQAAUGEOh/TOO1L37tJVV1V9dTDDkNLTLzwMw7+qFGZnzZqllStXurZvueUWXXTRRWrWrJm++OILr1UOAACgpJIvgBmG9NZb0mefeT7e0+pgWVnmjAjffy+tXy9Nniy1bCkNHMhSuVZTpTC7cOFCxcfHS5LS09P1/vvva+3atRo0aJD+8pe/eLWCAAAAxXl6AUyS7r1XOnLEPeiGhJReHWzOHKl5c3MYQUKCOQvCvHnSgQNSRETp67JUbnCrUpg9cuSIK8y+8847uvXWWzVw4EBNnTpVn5X1zyIAAAAvaNvWDKnF2e3SPfdIsbHmy15XXWWWp6ZKd9whff21NGuWWT5lSukwPHy4tHq1dOKEVHxSJpbKDX5VCrMNGzbUjz/+KElau3at+vfvL0kyDIMXwAAAgE/FxZkzFNjt5nbJwJmWVjTkIDXVDLgdOkj332++IObJ+PHSkCFSZKR05ZVm2dVXS1u2sBhDsKtSmP3d736nESNGaMCAATpx4oQGDRokSdqxY4cS6IcHAAA+lpws7d9vjnvdv78ocGZlmcG0uGPHpNBQ6frrpccf99yrWzy+bN9ufn78sfR//8dsBsGuSiuAPfvss2rZsqV+/PFHPfXUU6pbt64k6fDhw5o4caJXKwgAAOBJXFzpP/9nZhbNRFDcv/8t/a/vTbGx5gwFhYWle3WzsqS33y46j9XFgl+VwmxoaKjuvffeUuVTpky54AoBAABUlXM8bfFAa7dLHTsWbScnm+F0zx6zR7Z4SGV1Meup8DCD1atXKz8/3/V9eV+VNW/ePLVs2VIRERHq0aOHtm7dWuax1113nWw2W6mvG264odL3BQAA1cv5xtMWP+6660qXO1cXK67k6mIsqBBcAr6c7cqVK5WSkqKFCxeqR48emjNnjhITE/Xtt9+6Vhwr7s0331ReXp5r+8SJE+rUqZNuueWWCt8TAABUX+X1vJ5PXJz5Ipizb84Zhi++WHrhBXNBBWfPLUMQgkPAl7OdPXu2xo0bp6SkJF122WVauHChIiMjtXTpUo/HX3TRRWrcuLHrKz09XZGRkYRZAADgUlbPa2UVFkrPPSdFR0u3386CCsGoSmNmvSUvL0/btm3TtGnTXGUhISHq37+/tmzZUqFrpKWl6Y9//KPq1KnjcX9ubq5yc3Nd2zk5OZKk/Px817AJX3Lewx/3gm/QhtZHG1ofbWhtVmo/8wWwWpKKxho4Fzdt3NhQdrZkGEX77HZDLVoUyAKPdkH83YaVuU+Vwuzdd9+thIQE3X333W7l//jHP7Rnzx7NmTOnQtc5fvy4CgsLFRsb61YeGxurb7755rznb926VV9++aXSyhmwMnPmTM2YMaNU+fr16xUZGVmhenpDenq63+4F36ANrY82tD7a0Nqs0H67dkXLMHqVKp84cYcGDDig999vrnnzOkuyyWYzdOedO/Xf/x7Qf//r96oGhL/a8OzZsxU+tkph9o033vD4otfVV1+tJ598ssJh9kKlpaWpY8eO6t69e5nHTJs2TSkpKa7tnJwcxcfHa+DAgYqKivJ5HfPz85Wenq4BAwYoNDTU5/eD99GG1kcbWh9taG1War8rrpBSUw05HO69r/fee7ni4i7X0aO2Esd31ODBl/u7mn7n7zZ0/iW9IqoUZk+cOKH69euXKo+KitLx48crfJ3o6GjZ7XZlZ2e7lWdnZ6tx48blnnvmzBmtWLFCjz76aLnHhYeHKzw8vFR5aGioX3+h/H0/eB9taH20ofXRhtZmhfZr1cqcDcF9HlqbWrUKVVaWdNddRccahk0TJ9bS4ME15wUwf7VhZe5RpRXAEhIStHbt2lLl7733nlq3bl3h64SFhalr167KyMhwlTkcDmVkZKhnz57lnvvaa68pNzdXt912W8UrDgAAcB5lrS7maUEGXgALvCr1zKakpGjy5Mk6duyY+vXrJ0nKyMjQM888U+khBikpKRozZoy6deum7t27a86cOTpz5oySkpIkSaNHj1azZs00c+ZMt/PS0tI0dOhQXXzxxVV5BAAAgDJ5Wl2srAUZii+FC/+rUpi94447lJubq8cff1yPPfaYJKlly5ZasGCBRo8eXalrDRs2TMeOHdP06dN15MgRde7cWWvXrnW9FHbgwAGFlFhE+dtvv9WmTZu0fv36qlQfAACg0pwLMowda26HhHhekAH+VeWpue666y7dddddOnbsmGrXrq26detWuRKTJ0/W5MmTPe7buHFjqbJLLrlERsmJ3gAAAPyIKBIcqjRmVpIKCgr0/vvv680333QFy0OHDun06dNeqxwAAECwyMqSxo8v2jYM80WxrKzA1QlV7Jn94YcfdP311+vAgQPKzc3VgAEDVK9ePc2aNUu5ublauHCht+sJAAAQUOW9AMZQg8CpUs/sPffco27duunnn39W7dq1XeU333yz28wEAAAA1YXzBbDieAEs8KoUZj/66CM99NBDCgsLcytv2bKlDh486JWKAQAABBPnC2BOvAAWHKoUZh0OhwoLC0uVZ2VlqV69ehdcKQAAgGCUnCz9b8IlLV1aNActAqdKYXbgwIFu88nabDadPn1aqampGjx4sLfqBgAAEFTS0iTnwqV33GFuI7CqFGaffvppbd68WZdddpnOnTunESNGuIYYzJo1y9t1BAAACLiSsxk4HMxmEAyqNJtBfHy8vvjiC61cuVJffPGFTp8+reTkZI0cOdLthTAAAIDqgtkMglOlw2x+fr7at2+vd955RyNHjtTIkSN9US8AAICgwnK2wanSwwxCQ0N17tw5X9QFAAAgaDGbQXCq0pjZSZMmadasWSooKPB2fQAAACyB5WyDQ5XGzH722WfKyMjQ+vXr1bFjR9WpU8dt/5tvvumVygEAAASLspazTUykdzaQqhRmGzRooN///vfergsAAEDQ4gWw4FSpMOtwOPS3v/1N3333nfLy8tSvXz898sgjzGAAAACqPV4AC06VGjP7+OOP64EHHlDdunXVrFkz/f3vf9ekSZN8VTcAAICgERcnjRrlXnbbbfTKBlqlwuyLL76o+fPna926dXrrrbf09ttv6+WXX5ajZJ87AABANZOVJb30knvZP//JogmBVqkwe+DAAbflavv37y+bzaZDhw55vWIAAADBpLwxswicSoXZgoICRUREuJWFhoYqPz/fq5UCAAAINs4xs8UxZjbwKvUCmGEYuv322xUeHu4qO3funO6880636bmYmgsAAFQ3zkUTxo41t1k0IThUKsyOGTOmVNltt93mtcoAAABYBYsmBIdKhdlly5b5qh4AAABBjUUTglOVlrMFAACoaXgBLDgRZgEAACqAF8CCE2EWAACgApwvgDnxAlhwIMwCAABUAS+ABQfCLAAAQAWU9QJYyRXAsrKkDRtYGcxfCLMAAAAVUJEXwNLSpBYtpH79zM+0NP/WsSYizAIAAFRAeS+AHTsm/e1v5oIKzsDrcHjuuYV3EWYBAAAqIC5OGjXKvaxbN2n0aKlxY2nq1NLnMHWX71Vq0QQAAICaKitLeukl97JPPy36vkMH6auv3PczdZfv0TMLAABQAZ7GzErSXXdJe/dKX34pDRzovu+225i6y9cIswAAABVQ1pjZBx6QWrUye27ff999/z//yZhZXyPMAgAAVIBz0QS73dy2290XTWC528BgzCwAAEAFJSdLiYlmQE1IcB9C4Oy5LR5oGTPre/TMAgAAVEJcnHTddaXHwsbFSVOmFG2X7LmFbxBmAQAAfMDTy2LwPsIsAACAF2RlSc8+W7Rd1nK38C7CLAAAgBfwAlhgEGYBAAC8oLzlbuE7hFkAAAAviIuT+vd3L2PRBN8jzAIAAHgBiyYEBmEWAADACxgzGxiEWQAAAC9gzGxgEGYBAAC8gDGzgUGYBQAA8ALGzAYGYRYAAMALGDMbGIRZAAAAL2DMbGAQZgEAALwgLk6aMqVo226XFi1izKyvEWYBAAB8oOSQA/gGYRYAAMALsrKkZ58t2jYMacIEXgDzNcIsAACAF/ACWGAQZgEAALyAF8ACgzALAADgBSyaEBiEWQAAAC9g0YTAIMwCAAB4AWNmA4MwCwAA4AWMmQ0MwiwAAIAXMGY2MAizAAAAXsCY2cAgzAIAAHgBY2YDgzALAADgBYyZDYyAh9l58+apZcuWioiIUI8ePbR169Zyj//ll180adIkNWnSROHh4WrXrp3WrFnjp9oCAAB4xpjZwAhomF25cqVSUlKUmpqq7du3q1OnTkpMTNTRo0c9Hp+Xl6cBAwZo//79ev311/Xtt99qyZIlatasmZ9rDgAA4I4xs4FRK5A3nz17tsaNG6ekpCRJ0sKFC/Xuu+9q6dKluv/++0sdv3TpUv3000/6+OOPFRoaKklq2bKlP6sMAADgUXljZumd9Z2Ahdm8vDxt27ZN06ZNc5WFhISof//+2rJli8dzVq9erZ49e2rSpEn697//rUaNGmnEiBG67777ZLfbPZ6Tm5ur3Nxc13ZOTo4kKT8/X/n5+V58Is+c9/DHveAbtKH10YbWRxtaW01pv5YtJZutlgzD5ioLCTHUokWBrP7o/m7DytwnYGH2+PHjKiwsVGxsrFt5bGysvvnmG4/n7N27Vx988IFGjhypNWvWaM+ePZo4caLy8/OVmprq8ZyZM2dqxowZpcrXr1+vyMjIC3+QCkpPT/fbveAbtKH10YbWRxtaW3Vvv+PHI2QYA93KDMPQBx98oOjocwGqlXf5qw3Pnj1b4WMDOsygshwOh2JiYrR48WLZ7XZ17dpVBw8e1N/+9rcyw+y0adOUkpLi2s7JyVF8fLwGDhyoqKgon9c5Pz9f6enpGjBggGtoBKyFNrQ+2tD6aENrqyntt3GjTZLNrcwwQtSixW/Up48RmEp5ib/b0PmX9IoIWJiNjo6W3W5Xdna2W3l2drYaN27s8ZwmTZooNDTUbUjBpZdeqiNHjigvL09hYWGlzgkPD1d4eHip8tDQUL/+Qvn7fvA+2tD6aEProw2trbq336WXmlNzFR83a7dL7dvXUnV5bH+1YWXuEbDZDMLCwtS1a1dlZGS4yhwOhzIyMtSzZ0+P5/Tq1Ut79uyRo9h/Jd99952aNGniMcgCAAD4C1NzBUZAp+ZKSUnRkiVL9MILL2j37t266667dObMGdfsBqNHj3Z7Qeyuu+7STz/9pHvuuUffffed3n33XT3xxBOaNGlSoB4BAABAElNzBUpAx8wOGzZMx44d0/Tp03XkyBF17txZa9eudb0UduDAAYUUW0ojPj5e69at05QpU3TFFVeoWbNmuueee3TfffcF6hEAAAAkMTVXoAT8BbDJkydr8uTJHvdt3LixVFnPnj31ySef+LhWAAAAleNczrbkmFmWs/WtgC9nCwAAUB0wZjYwCLMAAABewJjZwCDMAgAAeEF5Y2bhO4RZAAAAL3COmS2OMbO+R5gFAADwAsbMBgZhFgAAwAsYMxsYhFkAAAAvYMxsYBBmAQAAvKBtW8lmcy8LCWHMrK8RZgEAAHzEMAJdg+qPMAsAAOAFmZmlw6thMMzA1wizAAAAXsDUXIFBmAUAAPACpuYKDMIsAACAFzA1V2AQZgEAALyAqbkCgzALAADgBUzNFRiEWQAAAB9hai7fI8wCAAB4AVNzBQZhFgAAwAuYmiswCLMAAABewNRcgUGYBQAA8AKm5goMwiwAAIAXMDVXYBBmAQAAvICpuQKDMAsAAOAjTM3le4RZAAAAL2BqrsAgzAIAAHgBwwwCgzALAADgIwwz8D3CLAAAgBcwzCAwCLMAAABewApggUGYBQAA8AJWAAsMwiwAAIAXsAJYYBBmAQAAvIAVwAKDMAsAAOAFTM0VGIRZAAAAH2FqLt8jzAIAAHgBU3MFBmEWAADACxhmEBiEWQAAAB9hmIHvEWYBAAC8gGEGgUGYBQAA8AKGGQQGYRYAAMBHGGbge4RZAAAAL2CYQWAQZgEAALyAYQaBQZgFAADwEYYZ+B5hFgAAwAsYZhAYhFkAAAAvYJhBYBBmAQAAfIRhBr5HmAUAAPAChhkEBmEWAADACxhmEBiEWQAAAB9hmIHvEWYBAAC8oCLDDLKypA0bzE9PzrcfpRFmAQAAvOB8wwzS0qQWLaR+/czPtDT3Y8+3H54RZgEAAHzE2VP75ZfSuHGSw2FuOxzShAlFPbCZmeXvR9kIswAAAF5Q1jCDW2+VOncuva+wUHrpJWnUKOmKKzzvZyaE86sV6AoAAABUB85hBiVD6ZYtZZ/zwANl72MmhIqhZxYAAMCH/t//k95/v/R4Wklq1Ei6+25p1arS+5kJoWIIswAAAF7gaZiBJP3ud2Yvq6d9r7wizZ0r1a/PggtVxTADAAAAL2jb1gytzpe4JMluLxoq4GnfJZcUnVtyiALDDCqGnlkAAAAviIuTFi82Q6pkfi5aZJaXt68sDDOoGHpmAQAAvCQ5WUpMNIcHJCS4h9Xy9pW34ELx47KyzGPbti0/CNckhFkAAAAvcvbEVmZf3bqej69Tx/w0DOmRR6THHjO/Dwkxe3qTk71SZUsjzAIAAATY6dOey7/8Ulq9Wnr5ZWnfvqJy56IKiYn00BJmAQAAAqysOWrvuKPsc5yLKtT0MBsUL4DNmzdPLVu2VEREhHr06KGtW7eWeezy5ctls9ncviIiIvxYWwAAAP8IDZVuukmaMcPzfucwhJos4GF25cqVSklJUWpqqrZv365OnTopMTFRR48eLfOcqKgoHT582PX1ww8/+LHGAAAA3lXWHLVvvin9+99S796ezztzxrf1soKAh9nZs2dr3LhxSkpK0mWXXaaFCxcqMjJSS5cuLfMcm82mxo0bu75iY2P9WGMAAADvcs5RW5zdLnXuXLS/JOahNQV0zGxeXp62bdumadOmucpCQkLUv39/bSlnIePTp0+rRYsWcjgcuvLKK/XEE0+oQ4cOHo/Nzc1Vbm6uazsnJ0eSlJ+fr/z8fC89Sdmc9/DHveAbtKH10YbWRxtaG+13frGx0oIFNk2caFdhoU12u6H58wsVG2soP18yf3S1JBWteWsYhvLzC+T8sWZlSXv22JSQYHh9HK2/27Ay97EZRuCm5D106JCaNWumjz/+WD179nSVT506VR9++KE+/fTTUuds2bJFmZmZuuKKK3Ty5Ek9/fTT+s9//qOvvvpKcR5a7pFHHtEMDwNN/vWvfykyMtK7DwQAAHABjh+P0OHDddSkyRlFR59zle/aFa2HH+5V6vjHHtukjh1PKD29uebP7yzDsMlmMzRx4k4NGHDAn1X3qrNnz2rEiBE6efKkoqKiyj3WcmG2pPz8fF166aUaPny4HnvssVL7PfXMxsfH6/jx4+f94XhDfn6+0tPTNWDAAIWGhvr8fvA+2tD6aEProw2tjfa7cJ99JvXq5d4zKxnavLlA0dFS+/a1ZBhF++x2Q5mZBV7rofV3G+bk5Cg6OrpCYTagwwyio6Nlt9uVnZ3tVp6dna3GjRtX6BqhoaHq0qWL9uzZ43F/eHi4wsPDPZ7nz18of98P3kcbWh9taH20obXRflVXrF+uGJsefTRUmzaVfnmssNCmH34IVatW3q2Hv9qwMvcI6AtgYWFh6tq1qzIyMlxlDodDGRkZbj215SksLNSuXbvUpEkTX1UTAAAgoDy9ACZJ69Z5ntGgJr0cFvDZDFJSUrRkyRK98MIL2r17t+666y6dOXNGSUlJkqTRo0e7vSD26KOPav369dq7d6+2b9+u2267TT/88IPGjh0bqEcAAAAIiNtvl15/3VxwobjADSL1v4CvADZs2DAdO3ZM06dP15EjR9S5c2etXbvWNd3WgQMHFFJsroqff/5Z48aN05EjR9SwYUN17dpVH3/8sS677LJAPQIAAIBPZWZ6Lh8zxgyuJcOrYdSc1cECHmYlafLkyZo8ebLHfRs3bnTbfvbZZ/Xss8/6oVYAAADBwTkPrcNRVGa3m0MJDh/2fE5NWR0s4MMMAAAAUL64OGnxYjPASubnokVm+enTns+pKauDBUXPLAAAAMqXnCwlJprDBxISioYQtG1rjpktPtSgJr0ARpgFAACwiLi4io2DrUkvgDHMAAAAwMIyM8t+AawmIMwCAABYWN26nst5AQwAAABBr6a/AEaYBQAAsDB6ZgEAAGBZ9MwCAADAspxTcxVXk6bmIswCAABUM0zNBQAAAEtgai4AAABYFi+AAQAAwLJ4AQwAAACWRc8sAAAALIueWQAAAFgWPbMAAACwLHpmAQAAYFn0zAIAAMCy6JkFAACAZVV0OdusLGnDBvOzpPL2BTvCLAAAQDVTckWwtDSpRQupXz/zMy2tYvusgDALAABgYedbzvb776Vx4ySHw9x2OKQJE8xe2I8+KnufVRBmAQAALKysF8C2bpVGjZKuuKJ02C0slHr3lq691vM+ZxC2glqBrgAAAACqrqwXwO67r/zz9u83x9Y6e2WLs9JMCPTMAgAAWFhZPbMxMdKUKdLf/+55/7Rp0qpVnvdZaSYEwiwAAICFldUzu2KFNHu2dPPNZg9scXa7NHGi1KSJ53PpmQUAAIBftG3rOay2bWt+HxcnLV5sljn3LVpklleHOWoJswAAABZWXlh1Sk42x8hu2GB+Jieb5dVh9TBeAAMAALC45GQpMdGchSAhwT3IOsXFlS6vDj2zhFkAAIBqwFNYPZ/q0DPLMAMAAIAaqjr0zBJmAQAAaih6ZgEAAGBZ9MwCAADAsuiZBQAAgGXRMwsAAADLomcWAAAAlkXPLAAAACyLnlkAAABYFj2zAAAAsCx6ZgEAAGBZ+/Z5Lt+/36/VuCCEWQAAAFgWYRYAAKCGatXKc3nLln6txgUhzAIAANRQvAAGAAAAy+IFMAAAAFgWPbMAAACwLHpmAQAAYFkV7ZnNypJ27YpWVpbv61RZhFkAAIAaqiI9s0uWSG3a1NLDD/dSQkItpaX5p24VRZgFAACoocpaNOHbb6V33pGGD5fGj5cMwyZJcjhsGj9eQdVDWyvQFQAAAEBwSU6W8vI873M4pC1bpFtu8W+dykLPLAAAQA1V1qIJeXlSXJyUmOjf+lQFYRYAAKCGKusFsIULpQMHpMce87w/mFYII8wCAADUUG3bSiEl0qDdLt1wg2SzWWMeWsIsAABADRUXJy1ebAZYyfxctMgsl6wxDy0vgAEAANRgycnm2Ng9e6SEhKIgK1mjZ5YwCwAAUMPFxbmHWCfnMASHo6jMbjdDb7BgmAEAAAA8KhqGYEgyP4sPQwgGhFkAAACUKTlZysws0GOPbVJmZoGSkwNdI3eEWQAAAJQrLk7q2PFEUPXIOgVFmJ03b55atmypiIgI9ejRQ1u3bq3QeStWrJDNZtPQoUN9W0EAAAAEpYCH2ZUrVyolJUWpqanavn27OnXqpMTERB09erTc8/bv3697771XvXv39lNNAQAAEGwCHmZnz56tcePGKSkpSZdddpkWLlyoyMhILV26tMxzCgsLNXLkSM2YMUOtW7f2Y20BAAAQTAI6NVdeXp62bdumadOmucpCQkLUv39/bdmypczzHn30UcXExCg5OVkfffRRuffIzc1Vbm6uazsnJ0eSlJ+fr/z8/At8gvNz3sMf94Jv0IbWRxtaH21obbSf9fm7DStzn4CG2ePHj6uwsFCxsbFu5bGxsfrmm288nrNp0yalpaVp586dFbrHzJkzNWPGjFLl69evV2RkZKXrXFXp6el+uxd8gza0PtrQ+mhDa6P9rM9fbXj27NkKH2upRRNOnTqlUaNGacmSJYqOjq7QOdOmTVNKSoprOycnR/Hx8Ro4cKCioqJ8VVWX/Px8paena8CAAQoNDfX5/eB9tKH10YbWRxtaG+1nff5uQ+df0isioGE2Ojpadrtd2dnZbuXZ2dlq3LhxqeO///577d+/X0OGDHGVOf63JEWtWrX07bffqk2bNm7nhIeHKzw8vNS1QkND/foL5e/7wftoQ+ujDa2PNrQ22s/6/NWGlblHQF8ACwsLU9euXZWRkeEqczgcysjIUM+ePUsd3759e+3atUs7d+50fd10003q27evdu7cqfj4eH9WHwAAAAEW8GEGKSkpGjNmjLp166bu3btrzpw5OnPmjJKSkiRJo0ePVrNmzTRz5kxFRETo8ssvdzu/QYMGklSqHAAAANVfwMPssGHDdOzYMU2fPl1HjhxR586dtXbtWtdLYQcOHFBISMBnEAMAAEAQCniYlaTJkydr8uTJHvdt3Lix3HOXL1/u/QoBAADAEujyBAAAgGURZgEAAGBZhFkAAABYFmEWAAAAlhUUL4D5k2EYkiq3ssSFyM/P19mzZ5WTk8NE0RZFG1ofbWh9tKG10X7W5+82dOY0Z24rT40Ls6dOnZIkFlgAAAAIcqdOnVL9+vXLPcZmVCTyViMOh0OHDh1SvXr1ZLPZfH6/nJwcxcfH68cff1RUVJTP7wfvow2tjza0PtrQ2mg/6/N3GxqGoVOnTqlp06bnXW+gxvXMhoSEKC4uzu/3jYqK4hfY4mhD66MNrY82tDbaz/r82Ybn65F14gUwAAAAWBZhFgAAAJZFmPWx8PBwpaamKjw8PNBVQRXRhtZHG1ofbWhttJ/1BXMb1rgXwAAAAFB90DMLAAAAyyLMAgAAwLIIswAAALAswiwAAAAsizDrBfPmzVPLli0VERGhHj16aOvWreUe/9prr6l9+/aKiIhQx44dtWbNGj/VFGWpTBsuWbJEvXv3VsOGDdWwYUP179//vG0O36vs76HTihUrZLPZNHToUN9WEOdV2Tb85ZdfNGnSJDVp0kTh4eFq164d/3saQJVtvzlz5uiSSy5R7dq1FR8frylTpujcuXN+qi1K+s9//qMhQ4aoadOmstlseuutt857zsaNG3XllVcqPDxcCQkJWr58uc/r6ZGBC7JixQojLCzMWLp0qfHVV18Z48aNMxo0aGBkZ2d7PH7z5s2G3W43nnrqKePrr782HnroISM0NNTYtWuXn2sOp8q24YgRI4x58+YZO3bsMHbv3m3cfvvtRv369Y2srCw/1xxOlW1Dp3379hnNmjUzevfubfz2t7/1T2XhUWXbMDc31+jWrZsxePBgY9OmTca+ffuMjRs3Gjt37vRzzWEYlW+/l19+2QgPDzdefvllY9++fca6deuMJk2aGFOmTPFzzeG0Zs0a48EHHzTefPNNQ5KxatWqco/fu3evERkZaaSkpBhff/218dxzzxl2u91Yu3atfypcDGH2AnXv3t2YNGmSa7uwsNBo2rSpMXPmTI/H33rrrcYNN9zgVtajRw9jwoQJPq0nylbZNiypoKDAqFevnvHCCy/4qoo4j6q0YUFBgXH11Vcbzz//vDFmzBjCbIBVtg0XLFhgtG7d2sjLy/NXFVGOyrbfpEmTjH79+rmVpaSkGL169fJpPVExFQmzU6dONTp06OBWNmzYMCMxMdGHNfOMYQYXIC8vT9u2bVP//v1dZSEhIerfv7+2bNni8ZwtW7a4HS9JiYmJZR4P36pKG5Z09uxZ5efn66KLLvJVNVGOqrbho48+qpiYGCUnJ/ujmihHVdpw9erV6tmzpyZNmqTY2FhdfvnleuKJJ1RYWOivauN/qtJ+V199tbZt2+YairB3716tWbNGgwcP9kudceGCKc/U8vsdq5Hjx4+rsLBQsbGxbuWxsbH65ptvPJ5z5MgRj8cfOXLEZ/VE2arShiXdd999atq0aalfavhHVdpw06ZNSktL086dO/1QQ5xPVdpw7969+uCDDzRy5EitWbNGe/bs0cSJE5Wfn6/U1FR/VBv/U5X2GzFihI4fP65rrrlGhmGooKBAd955px544AF/VBleUFaeycnJ0a+//qratWv7rS70zAIX4Mknn9SKFSu0atUqRUREBLo6qIBTp05p1KhRWrJkiaKjowNdHVSRw+FQTEyMFi9erK5du2rYsGF68MEHtXDhwkBXDRWwceNGPfHEE5o/f762b9+uN998U++++64ee+yxQFcNFkTP7AWIjo6W3W5Xdna2W3l2drYaN27s8ZzGjRtX6nj4VlXa0Onpp5/Wk08+qffff19XXHGFL6uJclS2Db///nvt379fQ4YMcZU5HA5JUq1atfTtt9+qTZs2vq003FTl97BJkyYKDQ2V3W53lV166aU6cuSI8vLyFBYW5tM6o0hV2u/hhx/WqFGjNHbsWElSx44ddebMGY0fP14PPvigQkLoawt2ZeWZqKgov/bKSvTMXpCwsDB17dpVGRkZrjKHw6GMjAz17NnT4zk9e/Z0O16S0tPTyzwevlWVNpSkp556So899pjWrl2rbt26+aOqKENl27B9+/batWuXdu7c6fq66aab1LdvX+3cuVPx8fH+rD5Utd/DXr16ac+ePa5/iEjSd999pyZNmhBk/awq7Xf27NlSgdX5DxPDMHxXWXhNUOUZv79yVs2sWLHCCA8PN5YvX258/fXXxvjx440GDRoYR44cMQzDMEaNGmXcf//9ruM3b95s1KpVy3j66aeN3bt3G6mpqUzNFWCVbcMnn3zSCAsLM15//XXj8OHDrq9Tp04F6hFqvMq2YUnMZhB4lW3DAwcOGPXq1TMmT55sfPvtt8Y777xjxMTEGH/9618D9Qg1WmXbLzU11ahXr57xyiuvGHv37jXWr19vtGnTxrj11lsD9Qg13qlTp4wdO3YYO3bsMCQZs2fPNnbs2GH88MMPhmEYxv3332+MGjXKdbxzaq6//OUvxu7du4158+YxNZeVPffcc0bz5s2NsLAwo3v37sYnn3zi2tenTx9jzJgxbse/+uqrRrt27YywsDCjQ4cOxrvvvuvnGqOkyrRhixYtDEmlvlJTU/1fcbhU9vewOMJscKhsG3788cdGjx49jPDwcKN169bG448/bhQUFPi51nCqTPvl5+cbjzzyiNGmTRsjIiLCiI+PNyZOnGj8/PPP/q84DMMwjA0bNnj8/zZnu40ZM8bo06dPqXM6d+5shIWFGa1btzaWLVvm93obhmHYDIP+fAAAAFgTY2YBAABgWYRZAAAAWBZhFgAAAJZFmAUAAIBlEWYBAABgWYRZAAAAWBZhFgAAAJZFmAUAAIBlEWYBoAaz2Wx66623JEn79++XzWbTzp07A1onAKgMwiwABMjtt98um80mm82m0NBQtWrVSlOnTtW5c+cCXTUAsIxaga4AANRk119/vZYtW6b8/Hxt27ZNY8aMkc1m06xZswJdNQCwBHpmASCAwsPD1bhxY8XHx2vo0KHq37+/0tPTJUkOh0MzZ85Uq1atVLt2bXXq1Emvv/662/lfffWVbrzxRkVFRalevXrq3bu3vv/+e0nSZ599pgEDBig6Olr169dXnz59tH37dr8/IwD4EmEWAILEl19+qY8//lhhYWGSpJkzZ+rFF1/UwoUL9dVXX2nKlCm67bbb9OGHH0qSDh48qGuvvVbh4eH64IMPtG3bNt1xxx0qKCiQJJ06dUpjxozRpk2b9Mknn6ht27YaPHiwTp06FbBnBABvY5gBAATQO++8o7p166qgoEC5ubkKCQnRP/7xD+Xm5uqJJ57Q+++/r549e0qSWrdurU2bNmnRokXq06eP5s2bp/r162vFihUKDQ2VJLVr18517X79+rnda/HixWrQoIE+/PBD3Xjjjf57SADwIcIsAARQ3759tWDBAp05c0bPPvusatWqpd///vf66quvdPbsWQ0YMMDt+Ly8PHXp0kWStHPnTvXu3dsVZEvKzs7WQw89pI0bN+ro0aMqLCzU2bNndeDAAZ8/FwD4C2EWAAKoTp06SkhIkCQtXbpUnTp1Ulpami6//HJJ0rvvvqtmzZq5nRMeHi5Jql27drnXHjNmjE6cOKG5c+eqRYsWCg8PV8+ePZWXl+eDJwGAwCDMAkCQCAkJ0QMPPKCUlBR99913Cg8P14EDB9SnTx+Px19xxRV64YUXlJ+f77F3dvPmzZo/f74GDx4sSfrxxx91/Phxnz4DAPgbL4ABQBC55ZZbZLfbtWjRIt17772aMmWKXnjhBX3//ffavn27nnvuOb3wwguSpMmTJysnJ0d//OMf9fnnnyszM1MvvfSSvv32W0lS27Zt9dJLL2n37t369NNPNXLkyPP25gKA1dAzCwBBpFatWpo8ebKeeuop7du3T40aNdLMmTO1d+9eNWjQQFdeeaUeeOABSdLFF1+sDz74QH/5y1/Up08f2e12de7cWb169ZIkpaWlafz48bryyisVHx+vJ554Qvfee28gHw8AvM5mGIYR6EoAAAAAVcEwAwAAAFgWYRYAAACWRZgFAACAZRFmAQAAYFmEWQAAAFgWYRYAAACWRZgFAACAZRFmAQAAYFmEWQAAAFgWYRYAAACWRZgFAACAZf1/vWTCgZSG978AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the Titanic dataset from a CSV file\n",
        "# Replace 'titanic.csv' with the actual file path\n",
        "df = pd.read_csv('/content/titanic.csv')\n",
        "\n",
        "# Display the first few rows to understand the dataset structure\n",
        "print(df.head())\n",
        "\n",
        "# Handle missing values\n",
        "# For numerical columns, we will fill missing values with the median of that column\n",
        "# For categorical columns, we will fill missing values with the mode (most frequent value)\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Apply imputer to numerical columns\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
        "\n",
        "# Apply imputer to categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
        "\n",
        "# Drop columns like 'Name', 'Ticket', 'Cabin' that are non-numeric or won't be used in the model\n",
        "df = df.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Encode categorical columns (like 'Sex', 'Embarked') into numeric using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the 'Sex' column (binary)\n",
        "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
        "\n",
        "# Encode the 'Embarked' column (categorical with more than 2 categories)\n",
        "df['Embarked'] = label_encoder.fit_transform(df['Embarked'])\n",
        "\n",
        "# Feature selection - Use all columns except 'Survived' for features\n",
        "X = df.drop(columns=['Survived'])  # Features (excluding target 'Survived')\n",
        "y = df['Survived']  # Target variable (Survived or not)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features (important for regularization in Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the solvers to be used\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "\n",
        "# Initialize a dictionary to store accuracies\n",
        "accuracies = {}\n",
        "\n",
        "# Train and evaluate the model using each solver\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=200)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies[solver] = accuracy\n",
        "\n",
        "# Print the accuracies for each solver\n",
        "for solver, accuracy in accuracies.items():\n",
        "    print(f\"Accuracy with solver '{solver}': {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTGZQiopK9O9",
        "outputId": "a130991c-6851-4288-c7e2-8cccb0babce7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "Accuracy with solver 'liblinear': 0.8101\n",
            "Accuracy with solver 'saga': 0.8101\n",
            "Accuracy with solver 'lbfgs': 0.8101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC).\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the Titanic dataset from a CSV file\n",
        "# Replace 'titanic.csv' with the actual file path\n",
        "df = pd.read_csv('/content/titanic.csv')\n",
        "\n",
        "# Display the first few rows to understand the dataset structure\n",
        "print(df.head())\n",
        "\n",
        "# Handle missing values\n",
        "# For numerical columns, we will fill missing values with the median of that column\n",
        "# For categorical columns, we will fill missing values with the mode (most frequent value)\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Apply imputer to numerical columns\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
        "\n",
        "# Apply imputer to categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
        "\n",
        "# Drop columns like 'Name', 'Ticket', 'Cabin' that are non-numeric or won't be used in the model\n",
        "df = df.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Encode categorical columns (like 'Sex', 'Embarked') into numeric using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the 'Sex' column (binary)\n",
        "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
        "\n",
        "# Encode the 'Embarked' column (categorical with more than 2 categories)\n",
        "df['Embarked'] = label_encoder.fit_transform(df['Embarked'])\n",
        "\n",
        "# Feature selection - Use all columns except 'Survived' for features\n",
        "X = df.drop(columns=['Survived'])  # Features (excluding target 'Survived')\n",
        "y = df['Survived']  # Target variable (Survived or not)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features (important for regularization in Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "# Print the MCC score\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7th01zswME_W",
        "outputId": "8547e71a-74a5-4139-deaa-3f15db7066d3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "Matthews Correlation Coefficient (MCC): 0.6059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the Titanic dataset from a CSV file\n",
        "# Replace 'titanic.csv' with the actual file path\n",
        "df = pd.read_csv('/content/titanic.csv')\n",
        "\n",
        "# Display the first few rows to understand the dataset structure\n",
        "print(df.head())\n",
        "\n",
        "# Handle missing values\n",
        "# For numerical columns, we will fill missing values with the median of that column\n",
        "# For categorical columns, we will fill missing values with the mode (most frequent value)\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Apply imputer to numerical columns\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
        "\n",
        "# Apply imputer to categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
        "\n",
        "# Drop columns like 'Name', 'Ticket', 'Cabin' that are non-numeric or won't be used in the model\n",
        "df = df.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Encode categorical columns (like 'Sex', 'Embarked') into numeric using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the 'Sex' column (binary)\n",
        "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
        "\n",
        "# Encode the 'Embarked' column (categorical with more than 2 categories)\n",
        "df['Embarked'] = label_encoder.fit_transform(df['Embarked'])\n",
        "\n",
        "# Feature selection - Use all columns except 'Survived' for features\n",
        "X = df.drop(columns=['Survived'])  # Features (excluding target 'Survived')\n",
        "y = df['Survived']  # Target variable (Survived or not)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train Logistic Regression on raw data\n",
        "model_raw = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "model_raw.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set for raw data\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for raw data\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "# Feature scaling (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create and train Logistic Regression on standardized data\n",
        "model_scaled = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set for standardized data\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "\n",
        "# Calculate accuracy for standardized data\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy without scaling (raw data): {accuracy_raw:.4f}\")\n",
        "print(f\"Accuracy with scaling (standardized data): {accuracy_scaled:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROteN7RpMa7a",
        "outputId": "f1d0f4b7-f408-4f79-cb22-b2c703874bf2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "Accuracy without scaling (raw data): 0.7989\n",
            "Accuracy with scaling (standardized data): 0.8101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the Titanic dataset from a CSV file\n",
        "# Replace 'titanic.csv' with the actual file path\n",
        "df = pd.read_csv('/content/titanic.csv')\n",
        "\n",
        "# Handle missing values\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Apply imputer to numerical columns\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
        "\n",
        "# Apply imputer to categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
        "\n",
        "# Drop columns like 'Name', 'Ticket', 'Cabin' that are non-numeric or won't be used in the model\n",
        "df = df.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Encode categorical columns (like 'Sex', 'Embarked') into numeric using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the 'Sex' column (binary)\n",
        "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
        "\n",
        "# Encode the 'Embarked' column (categorical with more than 2 categories)\n",
        "df['Embarked'] = label_encoder.fit_transform(df['Embarked'])\n",
        "\n",
        "# Feature selection - Use all columns except 'Survived' for features\n",
        "X = df.drop(columns=['Survived'])  # Features (excluding target 'Survived')\n",
        "y = df['Survived']  # Target variable (Survived or not)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling (important for regularization in Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "\n",
        "# Define the parameter grid for C (regularization strength)\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Perform GridSearchCV with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get the best parameter (optimal C value)\n",
        "best_C = grid_search.best_params_['C']\n",
        "print(f\"Optimal C value: {best_C}\")\n",
        "\n",
        "# Train the Logistic Regression model with the optimal C value\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of the model with optimal C: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbVx5wSuN1Q9",
        "outputId": "6e9577dd-b3d8-44c4-baad-af8f9dcd588d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal C value: 0.1\n",
            "Accuracy of the model with optimal C: 0.8045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Load the Titanic dataset (replace with the correct file path)\n",
        "df = pd.read_csv('/content/titanic.csv')\n",
        "\n",
        "# Handle missing values (for simplicity, let's use median for numerical and most frequent for categorical features)\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Apply imputer to numerical columns\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
        "\n",
        "# Apply imputer to categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
        "\n",
        "# Drop columns like 'Name', 'Ticket', 'Cabin' that are non-numeric or won't be used in the model\n",
        "df = df.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Encode categorical columns (like 'Sex', 'Embarked') into numeric using LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
        "df['Embarked'] = label_encoder.fit_transform(df['Embarked'])\n",
        "\n",
        "# Feature selection - Use all columns except 'Survived' for features\n",
        "X = df.drop(columns=['Survived'])  # Features (excluding target 'Survived')\n",
        "y = df['Survived']  # Target variable (Survived or not)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling (important for regularization in Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Save the trained model using joblib\n",
        "joblib.dump(log_reg, 'logistic_regression_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')  # Save the scaler as well\n",
        "\n",
        "# Load the saved model from disk\n",
        "loaded_model = joblib.load('logistic_regression_model.pkl')\n",
        "loaded_scaler = joblib.load('scaler.pkl')  # Load the saved scaler\n",
        "\n",
        "# Use the loaded model to make predictions on the test set\n",
        "X_test_scaled_loaded = loaded_scaler.transform(X_test)  # Scale the test data using the loaded scaler\n",
        "y_pred = loaded_model.predict(X_test_scaled_loaded)\n",
        "\n",
        "# Calculate and print the accuracy of the loaded model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of the loaded model: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZtpDT7WPbuM",
        "outputId": "9eadf61c-336f-447b-8b91-0a62e5ff435f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the loaded model: 0.8101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XLPsbpOlPuQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}